{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cluster import DBSCAN\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = [word.lower().strip(string.punctuation) for word in text.split()]\n",
    "    words = [word for word in words if word]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question_text_norm'] = data['question_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(data['question_text_norm'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for sent in corpus:\n",
    "    vocab.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {v for v,c in vocab.most_common(10000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab -= set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = gensim.models.Word2Vec(corpus, size=200, sg=1,max_vocab_size=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(vocab), 200))\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "for i,word in id2word.items():\n",
    "    try:\n",
    "        vec = ft[word]\n",
    "    except (KeyError, ValueError):\n",
    "        continue\n",
    "    \n",
    "    X[i] = vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.3, leaf_size=100, metric='cosine',\n",
       "    metric_params=None, min_samples=5, n_jobs=None, p=None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = DBSCAN(eps=0.3, leaf_size=100, metric='cosine')\n",
    "cluster.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(cluster.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = defaultdict(list)\n",
    "\n",
    "for i, cl in enumerate(cluster.labels_):\n",
    "    if cl != -1:\n",
    "        cls[cl].append(id2word[i])\n",
    "\n",
    "f = open('cluster.txt', 'w')\n",
    "for cl in cls:\n",
    "    f.write('### '+ str(cl) + ' ###\\n')\n",
    "    f.write('\\n'.join(cls[cl]))\n",
    "    f.write('\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictinary = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictinary.filter_extremes(no_above=0.3, no_below=10)\n",
    "dictinary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(35260 unique tokens: ['fours', 'rhinoplasty', 'ivf', 'mogul', 'wheatgrass']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in dictinary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusbo = [dictinary.doc2bow(text) for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    }
   ],
   "source": [
    "lda = gensim.models.LdaMulticore(corpusbo, 100, id2word=dictinary, passes=3, \n",
    "                                 chunksize=1000, iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.043*\"a\" + 0.039*\"case\" + 0.036*\"ideas\" + 0.033*\"for\" + 0.025*\"in\" + 0.024*\"color\" + 0.024*\"suggest\" + 0.022*\"of\" + 0.018*\"iran\" + 0.016*\"replace\"'),\n",
       " (1,\n",
       "  '0.047*\"to\" + 0.037*\"times\" + 0.030*\"it\" + 0.030*\"interview\" + 0.028*\"a\" + 0.028*\"difficult\" + 0.026*\"asked\" + 0.026*\"100\" + 0.024*\"stock\" + 0.023*\"in\"'),\n",
       " (2,\n",
       "  '0.089*\"buy\" + 0.074*\"to\" + 0.053*\"a\" + 0.033*\"successful\" + 0.025*\"in\" + 0.023*\"least\" + 0.020*\"pass\" + 0.020*\"for\" + 0.020*\"can\" + 0.019*\"policy\"'),\n",
       " (3,\n",
       "  '0.063*\"working\" + 0.050*\"medical\" + 0.041*\"care\" + 0.039*\"general\" + 0.033*\"yourself\" + 0.031*\"private\" + 0.025*\"large\" + 0.022*\"email\" + 0.021*\"factors\" + 0.020*\"for\"'),\n",
       " (4,\n",
       "  '0.090*\"in\" + 0.068*\"for\" + 0.055*\"university\" + 0.048*\"study\" + 0.041*\"students\" + 0.041*\"class\" + 0.024*\"of\" + 0.024*\"technology\" + 0.023*\"how\" + 0.022*\"which\"'),\n",
       " (5,\n",
       "  '0.159*\"other\" + 0.070*\"bad\" + 0.046*\"and\" + 0.042*\"car\" + 0.040*\"each\" + 0.027*\"are\" + 0.025*\"humans\" + 0.023*\"why\" + 0.022*\"of\" + 0.021*\"australia\"'),\n",
       " (6,\n",
       "  '0.056*\"to\" + 0.034*\"in\" + 0.034*\"a\" + 0.032*\"open\" + 0.032*\"idea\" + 0.028*\"culture\" + 0.026*\"internet\" + 0.026*\"for\" + 0.023*\"team\" + 0.022*\"how\"'),\n",
       " (7,\n",
       "  '0.094*\"now\" + 0.072*\"right\" + 0.057*\"to\" + 0.038*\"game\" + 0.034*\"left\" + 0.033*\"stay\" + 0.031*\"in\" + 0.023*\"once\" + 0.021*\"you\\'ve\" + 0.018*\"a\"'),\n",
       " (8,\n",
       "  '0.221*\"your\" + 0.077*\"you\" + 0.071*\"life\" + 0.055*\"ever\" + 0.031*\"have\" + 0.029*\"in\" + 0.026*\"thing\" + 0.024*\"experience\" + 0.022*\"was\" + 0.018*\"on\"'),\n",
       " (9,\n",
       "  '0.045*\"of\" + 0.032*\"personality\" + 0.032*\"a\" + 0.022*\"disorder\" + 0.021*\"results\" + 0.020*\"looks\" + 0.019*\"with\" + 0.018*\"in\" + 0.017*\"advantage\" + 0.017*\"eu\"'),\n",
       " (10,\n",
       "  '0.065*\"to\" + 0.055*\"take\" + 0.052*\"a\" + 0.046*\"year\" + 0.045*\"it\" + 0.043*\"years\" + 0.040*\"how\" + 0.036*\"for\" + 0.035*\"school\" + 0.035*\"long\"'),\n",
       " (11,\n",
       "  '0.068*\"in\" + 0.057*\"against\" + 0.043*\"are\" + 0.039*\"why\" + 0.037*\"indians\" + 0.033*\"and\" + 0.029*\"popular\" + 0.025*\"religion\" + 0.023*\"bangalore\" + 0.023*\"marriage\"'),\n",
       " (12,\n",
       "  '0.041*\"america\" + 0.039*\"states\" + 0.036*\"of\" + 0.035*\"president\" + 0.033*\"united\" + 0.033*\"why\" + 0.031*\"in\" + 0.030*\"to\" + 0.026*\"understand\" + 0.025*\"and\"'),\n",
       " (13,\n",
       "  '0.068*\"book\" + 0.054*\"to\" + 0.049*\"books\" + 0.047*\"for\" + 0.045*\"career\" + 0.039*\"read\" + 0.039*\"course\" + 0.033*\"best\" + 0.032*\"in\" + 0.032*\"which\"'),\n",
       " (14,\n",
       "  '0.305*\"who\" + 0.059*\"a\" + 0.038*\"age\" + 0.030*\"in\" + 0.030*\"win\" + 0.025*\"of\" + 0.022*\"person\" + 0.021*\"or\" + 0.020*\"would\" + 0.017*\"was\"'),\n",
       " (15,\n",
       "  '0.061*\"of\" + 0.031*\"method\" + 0.030*\"a\" + 0.027*\"and\" + 0.023*\"key\" + 0.023*\"points\" + 0.021*\"step\" + 0.021*\"to\" + 0.020*\"by\" + 0.018*\"surface\"'),\n",
       " (16,\n",
       "  '0.099*\"in\" + 0.051*\"to\" + 0.048*\"are\" + 0.039*\"public\" + 0.029*\"of\" + 0.029*\"industry\" + 0.026*\"visit\" + 0.026*\"places\" + 0.022*\"nuclear\" + 0.021*\"father\"'),\n",
       " (17,\n",
       "  '0.071*\"facebook\" + 0.068*\"of\" + 0.042*\"a\" + 0.033*\"nothing\" + 0.031*\"in\" + 0.025*\"tamil\" + 0.025*\"on\" + 0.025*\"importance\" + 0.025*\"page\" + 0.021*\"sentence\"'),\n",
       " (18,\n",
       "  '0.068*\"of\" + 0.050*\"are\" + 0.043*\"wrong\" + 0.035*\"law\" + 0.029*\"required\" + 0.028*\"air\" + 0.026*\"benefits\" + 0.024*\"a\" + 0.023*\"in\" + 0.022*\"rather\"'),\n",
       " (19,\n",
       "  '0.078*\"canada\" + 0.059*\"card\" + 0.053*\"in\" + 0.046*\"party\" + 0.032*\"a\" + 0.030*\"credit\" + 0.027*\"for\" + 0.024*\"to\" + 0.018*\"from\" + 0.017*\"kolkata\"'),\n",
       " (20,\n",
       "  '0.109*\"a\" + 0.081*\"girl\" + 0.033*\"consider\" + 0.032*\"information\" + 0.032*\"to\" + 0.029*\"for\" + 0.023*\"boy\" + 0.022*\"non\" + 0.022*\"can\" + 0.021*\"marry\"'),\n",
       " (21,\n",
       "  '0.145*\"of\" + 0.079*\"meaning\" + 0.036*\"a\" + 0.029*\"prime\" + 0.023*\"in\" + 0.023*\"minister\" + 0.020*\"pakistani\" + 0.014*\"royal\" + 0.014*\"and\" + 0.013*\"stone\"'),\n",
       " (22,\n",
       "  '0.274*\"you\" + 0.124*\"do\" + 0.052*\"how\" + 0.042*\"think\" + 0.036*\"a\" + 0.028*\"to\" + 0.022*\"that\" + 0.021*\"know\" + 0.020*\"about\" + 0.019*\"have\"'),\n",
       " (23,\n",
       "  '0.039*\"muslims\" + 0.039*\"of\" + 0.038*\"app\" + 0.036*\"are\" + 0.032*\"management\" + 0.031*\"health\" + 0.025*\"gay\" + 0.024*\"that\" + 0.023*\"in\" + 0.020*\"why\"'),\n",
       " (24,\n",
       "  '0.078*\"in\" + 0.057*\"believe\" + 0.053*\"show\" + 0.053*\"power\" + 0.045*\"tv\" + 0.041*\"of\" + 0.037*\"series\" + 0.029*\"fight\" + 0.019*\"treatment\" + 0.019*\"why\"'),\n",
       " (25,\n",
       "  '0.051*\"of\" + 0.045*\"a\" + 0.040*\"social\" + 0.034*\"how\" + 0.033*\"big\" + 0.032*\"body\" + 0.029*\"media\" + 0.028*\"process\" + 0.026*\"small\" + 0.025*\"can\"'),\n",
       " (26,\n",
       "  '0.271*\"i\" + 0.113*\"my\" + 0.072*\"how\" + 0.064*\"do\" + 0.056*\"can\" + 0.033*\"should\" + 0.033*\"to\" + 0.022*\"and\" + 0.022*\"a\" + 0.021*\"get\"'),\n",
       " (27,\n",
       "  '0.090*\"different\" + 0.065*\"of\" + 0.052*\"in\" + 0.041*\"movie\" + 0.035*\"part\" + 0.032*\"uk\" + 0.031*\"are\" + 0.029*\"control\" + 0.024*\"said\" + 0.022*\"a\"'),\n",
       " (28,\n",
       "  '0.046*\"chinese\" + 0.041*\"google\" + 0.034*\"how\" + 0.033*\"with\" + 0.032*\"deal\" + 0.030*\"of\" + 0.029*\"do\" + 0.022*\"themselves\" + 0.020*\"example\" + 0.018*\"may\"'),\n",
       " (29,\n",
       "  '0.097*\"in\" + 0.054*\"2017\" + 0.053*\"of\" + 0.030*\"eat\" + 0.028*\"score\" + 0.026*\"face\" + 0.023*\"rank\" + 0.022*\"society\" + 0.020*\"speed\" + 0.019*\"cat\"'),\n",
       " (30,\n",
       "  '0.088*\"me\" + 0.087*\"does\" + 0.065*\"it\" + 0.065*\"mean\" + 0.043*\"help\" + 0.040*\"a\" + 0.031*\"friend\" + 0.030*\"to\" + 0.024*\"look\" + 0.020*\"when\"'),\n",
       " (31,\n",
       "  '0.040*\"started\" + 0.039*\"islam\" + 0.033*\"of\" + 0.029*\"democrats\" + 0.028*\"why\" + 0.027*\"in\" + 0.025*\"issue\" + 0.025*\"temperature\" + 0.025*\"that\" + 0.023*\"straight\"'),\n",
       " (32,\n",
       "  '0.064*\"for\" + 0.059*\"are\" + 0.042*\"tips\" + 0.041*\"taking\" + 0.035*\"everyone\" + 0.031*\"starting\" + 0.028*\"useful\" + 0.023*\"chemical\" + 0.022*\"of\" + 0.021*\"at\"'),\n",
       " (33,\n",
       "  '0.067*\"to\" + 0.045*\"a\" + 0.043*\"legal\" + 0.039*\"in\" + 0.036*\"for\" + 0.035*\"personal\" + 0.035*\"project\" + 0.028*\"interest\" + 0.022*\"it\" + 0.021*\"strategy\"'),\n",
       " (34,\n",
       "  '0.073*\"in\" + 0.041*\"for\" + 0.041*\"of\" + 0.034*\"delhi\" + 0.033*\"marketing\" + 0.029*\"group\" + 0.026*\"colleges\" + 0.024*\"are\" + 0.024*\"plan\" + 0.020*\"depression\"'),\n",
       " (35,\n",
       "  '0.071*\"in\" + 0.053*\"2018\" + 0.044*\"exam\" + 0.037*\"jee\" + 0.035*\"for\" + 0.034*\"marks\" + 0.033*\"how\" + 0.026*\"can\" + 0.023*\"related\" + 0.020*\"treat\"'),\n",
       " (36,\n",
       "  '0.166*\"make\" + 0.074*\"money\" + 0.065*\"how\" + 0.061*\"online\" + 0.055*\"can\" + 0.045*\"a\" + 0.037*\"to\" + 0.035*\"account\" + 0.021*\"do\" + 0.018*\"earn\"'),\n",
       " (37,\n",
       "  '0.144*\"start\" + 0.125*\"business\" + 0.058*\"hate\" + 0.048*\"in\" + 0.034*\"for\" + 0.028*\"do\" + 0.026*\"are\" + 0.025*\"dating\" + 0.022*\"why\" + 0.018*\"perfect\"'),\n",
       " (38,\n",
       "  '0.091*\"trump\" + 0.034*\"to\" + 0.032*\"that\" + 0.029*\"and\" + 0.027*\"donald\" + 0.026*\"of\" + 0.021*\"biggest\" + 0.019*\"how\" + 0.017*\"does\" + 0.017*\"together\"'),\n",
       " (39,\n",
       "  '0.096*\"in\" + 0.072*\"job\" + 0.059*\"a\" + 0.054*\"college\" + 0.054*\"engineering\" + 0.049*\"for\" + 0.037*\"doing\" + 0.023*\"get\" + 0.023*\"jobs\" + 0.021*\"after\"'),\n",
       " (40,\n",
       "  '0.026*\"goal\" + 0.025*\"in\" + 0.022*\"why\" + 0.018*\"of\" + 0.017*\"are\" + 0.017*\"a\" + 0.016*\"how\" + 0.015*\"beach\" + 0.013*\"and\" + 0.012*\"adam\"'),\n",
       " (41,\n",
       "  '0.038*\"how\" + 0.037*\"java\" + 0.035*\"gain\" + 0.028*\"nit\" + 0.026*\"evidence\" + 0.025*\"in\" + 0.025*\"net\" + 0.017*\"for\" + 0.017*\"industrial\" + 0.017*\"to\"'),\n",
       " (42,\n",
       "  '0.097*\"to\" + 0.041*\"parents\" + 0.034*\"children\" + 0.033*\"it\" + 0.030*\"a\" + 0.028*\"move\" + 0.024*\"mind\" + 0.022*\"city\" + 0.022*\"force\" + 0.018*\"young\"'),\n",
       " (43,\n",
       "  '0.052*\"a\" + 0.044*\"call\" + 0.033*\"of\" + 0.030*\"in\" + 0.028*\"police\" + 0.027*\"universe\" + 0.026*\"act\" + 0.019*\"officer\" + 0.019*\"physical\" + 0.019*\"an\"'),\n",
       " (44,\n",
       "  '0.057*\"to\" + 0.038*\"question\" + 0.037*\"ask\" + 0.035*\"answer\" + 0.034*\"anything\" + 0.026*\"why\" + 0.026*\"talk\" + 0.025*\"a\" + 0.020*\"period\" + 0.019*\"that\"'),\n",
       " (45,\n",
       "  '0.053*\"in\" + 0.049*\"market\" + 0.044*\"video\" + 0.034*\"leave\" + 0.031*\"share\" + 0.029*\"are\" + 0.028*\"effect\" + 0.027*\"for\" + 0.026*\"on\" + 0.024*\"israel\"'),\n",
       " (46,\n",
       "  '0.080*\"of\" + 0.043*\"americans\" + 0.032*\"value\" + 0.024*\"exist\" + 0.023*\"why\" + 0.022*\"are\" + 0.021*\"in\" + 0.021*\"matter\" + 0.019*\"thoughts\" + 0.019*\"do\"'),\n",
       " (47,\n",
       "  '0.071*\"a\" + 0.065*\"name\" + 0.060*\"of\" + 0.038*\"house\" + 0.035*\"to\" + 0.032*\"light\" + 0.025*\"germany\" + 0.025*\"in\" + 0.020*\"sound\" + 0.019*\"red\"'),\n",
       " (48,\n",
       "  '0.088*\"in\" + 0.061*\"found\" + 0.055*\"low\" + 0.051*\"admission\" + 0.040*\"of\" + 0.040*\"a\" + 0.027*\"front\" + 0.021*\"to\" + 0.019*\"for\" + 0.016*\"with\"'),\n",
       " (49,\n",
       "  '0.058*\"number\" + 0.047*\"phone\" + 0.045*\"10\" + 0.044*\"top\" + 0.038*\"of\" + 0.034*\"are\" + 0.031*\"etc\" + 0.031*\"in\" + 0.026*\"visa\" + 0.026*\"mobile\"'),\n",
       " (50,\n",
       "  '0.118*\"of\" + 0.047*\"food\" + 0.046*\"kind\" + 0.045*\"history\" + 0.044*\"in\" + 0.038*\"are\" + 0.027*\"and\" + 0.025*\"opinion\" + 0.021*\"three\" + 0.021*\"self\"'),\n",
       " (51,\n",
       "  '0.073*\"science\" + 0.062*\"computer\" + 0.055*\"a\" + 0.044*\"of\" + 0.034*\"in\" + 0.034*\"hair\" + 0.034*\"political\" + 0.031*\"salary\" + 0.030*\"story\" + 0.026*\"night\"'),\n",
       " (52,\n",
       "  '0.230*\"and\" + 0.174*\"between\" + 0.089*\"difference\" + 0.046*\"a\" + 0.045*\"relationship\" + 0.037*\"both\" + 0.024*\"military\" + 0.017*\"two\" + 0.015*\"there\" + 0.014*\"what\\'s\"'),\n",
       " (53,\n",
       "  '0.107*\"are\" + 0.083*\"of\" + 0.054*\"ways\" + 0.041*\"major\" + 0.040*\"in\" + 0.038*\"to\" + 0.031*\"causes\" + 0.030*\"and\" + 0.027*\"available\" + 0.023*\"types\"'),\n",
       " (54,\n",
       "  '0.093*\"go\" + 0.076*\"to\" + 0.040*\"a\" + 0.039*\"3\" + 0.031*\"5\" + 0.029*\"next\" + 0.028*\"4\" + 0.026*\"for\" + 0.025*\"months\" + 0.020*\"back\"'),\n",
       " (55,\n",
       "  '0.064*\"a\" + 0.043*\"paper\" + 0.038*\"national\" + 0.026*\"fun\" + 0.024*\"in\" + 0.023*\"election\" + 0.022*\"scientific\" + 0.022*\"of\" + 0.021*\"how\" + 0.019*\"to\"'),\n",
       " (56,\n",
       "  '0.074*\"feel\" + 0.063*\"i\\'m\" + 0.058*\"to\" + 0.051*\"i\" + 0.045*\"and\" + 0.042*\"stop\" + 0.039*\"do\" + 0.026*\"it\" + 0.026*\"how\" + 0.022*\"myself\"'),\n",
       " (57,\n",
       "  '0.071*\"cause\" + 0.048*\"a\" + 0.036*\"present\" + 0.036*\"can\" + 0.030*\"of\" + 0.029*\"how\" + 0.025*\"and\" + 0.022*\"to\" + 0.020*\"does\" + 0.017*\"disease\"'),\n",
       " (58,\n",
       "  '0.060*\"student\" + 0.057*\"a\" + 0.042*\"learning\" + 0.038*\"to\" + 0.034*\"for\" + 0.028*\"research\" + 0.027*\"program\" + 0.023*\"in\" + 0.022*\"an\" + 0.021*\"how\"'),\n",
       " (59,\n",
       "  '0.044*\"to\" + 0.043*\"considered\" + 0.039*\"end\" + 0.033*\"why\" + 0.029*\"are\" + 0.026*\"and\" + 0.025*\"similar\" + 0.022*\"in\" + 0.022*\"be\" + 0.022*\"of\"'),\n",
       " (60,\n",
       "  '0.080*\"sex\" + 0.078*\"having\" + 0.045*\"with\" + 0.045*\"normal\" + 0.043*\"a\" + 0.038*\"have\" + 0.036*\"to\" + 0.035*\"it\" + 0.032*\"problem\" + 0.027*\"blood\"'),\n",
       " (61,\n",
       "  '0.072*\"happens\" + 0.056*\"a\" + 0.044*\"month\" + 0.042*\"in\" + 0.040*\"per\" + 0.034*\"when\" + 0.030*\"of\" + 0.028*\"phd\" + 0.020*\"if\" + 0.018*\"to\"'),\n",
       " (62,\n",
       "  '0.067*\"in\" + 0.056*\"china\" + 0.044*\"usa\" + 0.039*\"and\" + 0.034*\"north\" + 0.031*\"south\" + 0.029*\"why\" + 0.028*\"of\" + 0.023*\"korea\" + 0.018*\"are\"'),\n",
       " (63,\n",
       "  '0.032*\"how\" + 0.032*\"to\" + 0.032*\"18\" + 0.023*\"python\" + 0.022*\"league\" + 0.022*\"damage\" + 0.022*\"in\" + 0.019*\"touch\" + 0.019*\"perform\" + 0.016*\"of\"'),\n",
       " (64,\n",
       "  '0.053*\"away\" + 0.052*\"of\" + 0.049*\"youtube\" + 0.033*\"are\" + 0.028*\"completely\" + 0.027*\"videos\" + 0.024*\"from\" + 0.021*\"parts\" + 0.021*\"and\" + 0.019*\"on\"'),\n",
       " (65,\n",
       "  '0.151*\"much\" + 0.099*\"how\" + 0.051*\"to\" + 0.043*\"too\" + 0.042*\"a\" + 0.034*\"pay\" + 0.033*\"cost\" + 0.031*\"does\" + 0.031*\"in\" + 0.026*\"it\"'),\n",
       " (66,\n",
       "  '0.161*\"if\" + 0.127*\"would\" + 0.075*\"be\" + 0.061*\"a\" + 0.050*\"to\" + 0.038*\"it\" + 0.034*\"will\" + 0.023*\"of\" + 0.022*\"and\" + 0.019*\"happen\"'),\n",
       " (67,\n",
       "  '0.102*\"getting\" + 0.049*\"of\" + 0.034*\"foreign\" + 0.034*\"a\" + 0.034*\"from\" + 0.031*\"prevent\" + 0.028*\"chance\" + 0.026*\"chances\" + 0.025*\"in\" + 0.025*\"are\"'),\n",
       " (68,\n",
       "  '0.062*\"keep\" + 0.052*\"website\" + 0.048*\"for\" + 0.036*\"to\" + 0.028*\"a\" + 0.026*\"best\" + 0.025*\"daily\" + 0.023*\"which\" + 0.023*\"coaching\" + 0.021*\"provide\"'),\n",
       " (69,\n",
       "  '0.091*\"of\" + 0.074*\"in\" + 0.064*\"are\" + 0.063*\"data\" + 0.050*\"common\" + 0.042*\"and\" + 0.039*\"muslim\" + 0.030*\"terms\" + 0.020*\"advantages\" + 0.017*\"specific\"'),\n",
       " (70,\n",
       "  '0.111*\"even\" + 0.048*\"to\" + 0.045*\"why\" + 0.031*\"though\" + 0.028*\"it\" + 0.028*\"a\" + 0.023*\"head\" + 0.022*\"according\" + 0.020*\"it\\'s\" + 0.020*\"not\"'),\n",
       " (71,\n",
       "  '0.041*\"to\" + 0.039*\"how\" + 0.034*\"writing\" + 0.032*\"development\" + 0.030*\"iit\" + 0.029*\"can\" + 0.029*\"android\" + 0.029*\"for\" + 0.029*\"build\" + 0.024*\"in\"'),\n",
       " (72,\n",
       "  '0.059*\"to\" + 0.048*\"countries\" + 0.043*\"american\" + 0.038*\"in\" + 0.035*\"and\" + 0.035*\"country\" + 0.035*\"family\" + 0.031*\"why\" + 0.024*\"travel\" + 0.019*\"are\"'),\n",
       " (73,\n",
       "  '0.128*\"things\" + 0.073*\"are\" + 0.054*\"done\" + 0.052*\"to\" + 0.031*\"do\" + 0.028*\"that\" + 0.027*\"in\" + 0.019*\"of\" + 0.017*\"a\" + 0.015*\"on\"'),\n",
       " (74,\n",
       "  '0.124*\"where\" + 0.101*\"can\" + 0.098*\"i\" + 0.077*\"find\" + 0.049*\"in\" + 0.044*\"a\" + 0.042*\"how\" + 0.035*\"get\" + 0.034*\"for\" + 0.028*\"free\"'),\n",
       " (75,\n",
       "  '0.074*\"in\" + 0.051*\"for\" + 0.047*\"makes\" + 0.045*\"are\" + 0.032*\"physics\" + 0.032*\"to\" + 0.032*\"enough\" + 0.025*\"courses\" + 0.025*\"u.s\" + 0.019*\"chemistry\"'),\n",
       " (76,\n",
       "  '0.161*\"new\" + 0.098*\"a\" + 0.057*\"in\" + 0.055*\"degree\" + 0.039*\"to\" + 0.021*\"for\" + 0.015*\"york\" + 0.013*\"funds\" + 0.013*\"with\" + 0.013*\"how\"'),\n",
       " (77,\n",
       "  '0.053*\"important\" + 0.050*\"of\" + 0.048*\"girls\" + 0.044*\"why\" + 0.032*\"are\" + 0.031*\"average\" + 0.028*\"lot\" + 0.025*\"do\" + 0.022*\"guys\" + 0.022*\"past\"'),\n",
       " (78,\n",
       "  '0.097*\"change\" + 0.091*\"our\" + 0.076*\"system\" + 0.061*\"of\" + 0.049*\"we\" + 0.046*\"how\" + 0.034*\"in\" + 0.027*\"can\" + 0.024*\"and\" + 0.015*\"does\"'),\n",
       " (79,\n",
       "  '0.031*\"green\" + 0.031*\"buying\" + 0.030*\"football\" + 0.029*\"are\" + 0.029*\"in\" + 0.028*\"of\" + 0.022*\"selling\" + 0.021*\"for\" + 0.020*\"mark\" + 0.018*\"materials\"'),\n",
       " (80,\n",
       "  '0.273*\"some\" + 0.218*\"are\" + 0.084*\"of\" + 0.036*\"good\" + 0.028*\"that\" + 0.026*\"examples\" + 0.025*\"great\" + 0.020*\"for\" + 0.017*\"kids\" + 0.016*\"in\"'),\n",
       " (81,\n",
       "  '0.044*\"god\" + 0.035*\"word\" + 0.035*\"of\" + 0.033*\"why\" + 0.031*\"movies\" + 0.030*\"and\" + 0.026*\"in\" + 0.025*\"term\" + 0.023*\"are\" + 0.021*\"jews\"'),\n",
       " (82,\n",
       "  '0.069*\"company\" + 0.065*\"a\" + 0.049*\"software\" + 0.036*\"for\" + 0.036*\"service\" + 0.032*\"design\" + 0.030*\"in\" + 0.027*\"and\" + 0.025*\"how\" + 0.025*\"seen\"'),\n",
       " (83,\n",
       "  '0.039*\"financial\" + 0.036*\"close\" + 0.031*\"are\" + 0.031*\"of\" + 0.030*\"christian\" + 0.029*\"drink\" + 0.029*\"a\" + 0.025*\"bill\" + 0.022*\"and\" + 0.018*\"signs\"'),\n",
       " (84,\n",
       "  '0.057*\"a\" + 0.048*\"weight\" + 0.043*\"female\" + 0.042*\"male\" + 0.040*\"lose\" + 0.035*\"lost\" + 0.026*\"to\" + 0.024*\"smart\" + 0.022*\"sometimes\" + 0.022*\"almost\"'),\n",
       " (85,\n",
       "  '0.109*\"her\" + 0.078*\"she\" + 0.046*\"to\" + 0.041*\"test\" + 0.034*\"for\" + 0.030*\"a\" + 0.024*\"effective\" + 0.024*\"allowed\" + 0.020*\"wife\" + 0.019*\"size\"'),\n",
       " (86,\n",
       "  '0.070*\"he\" + 0.058*\"his\" + 0.043*\"had\" + 0.040*\"a\" + 0.039*\"been\" + 0.030*\"and\" + 0.029*\"him\" + 0.029*\"has\" + 0.028*\"that\" + 0.027*\"to\"'),\n",
       " (87,\n",
       "  '0.076*\"why\" + 0.060*\"they\" + 0.060*\"do\" + 0.058*\"people\" + 0.041*\"are\" + 0.040*\"to\" + 0.031*\"women\" + 0.030*\"and\" + 0.024*\"their\" + 0.023*\"so\"'),\n",
       " (88,\n",
       "  '0.181*\"someone\" + 0.113*\"to\" + 0.087*\"give\" + 0.040*\"a\" + 0.028*\"can\" + 0.026*\"advice\" + 0.020*\"for\" + 0.020*\"moving\" + 0.019*\"who\" + 0.018*\"land\"'),\n",
       " (89,\n",
       "  '0.049*\"skin\" + 0.035*\"inside\" + 0.031*\"a\" + 0.030*\"why\" + 0.026*\"battery\" + 0.023*\"how\" + 0.022*\"to\" + 0.019*\"writer\" + 0.018*\"saw\" + 0.018*\"dont\"'),\n",
       " (90,\n",
       "  '0.110*\"a\" + 0.063*\"to\" + 0.052*\"man\" + 0.038*\"woman\" + 0.038*\"of\" + 0.034*\"music\" + 0.031*\"date\" + 0.030*\"it\" + 0.028*\"favorite\" + 0.021*\"rid\"'),\n",
       " (91,\n",
       "  '0.073*\"of\" + 0.056*\"in\" + 0.052*\"living\" + 0.044*\"join\" + 0.042*\"form\" + 0.026*\"correct\" + 0.025*\"price\" + 0.023*\"population\" + 0.022*\"a\" + 0.020*\"how\"'),\n",
       " (92,\n",
       "  '0.060*\"learn\" + 0.048*\"to\" + 0.045*\"english\" + 0.043*\"a\" + 0.043*\"language\" + 0.042*\"war\" + 0.039*\"off\" + 0.025*\"bank\" + 0.024*\"in\" + 0.022*\"isn\\'t\"'),\n",
       " (93,\n",
       "  '0.066*\"day\" + 0.049*\"a\" + 0.045*\"every\" + 0.045*\"of\" + 0.030*\"earth\" + 0.030*\"on\" + 0.028*\"called\" + 0.024*\"why\" + 0.023*\"wear\" + 0.021*\"modern\"'),\n",
       " (94,\n",
       "  '0.066*\"prepare\" + 0.059*\"for\" + 0.052*\"how\" + 0.031*\"fall\" + 0.028*\"and\" + 0.025*\"of\" + 0.024*\"coming\" + 0.024*\"hurt\" + 0.021*\"do\" + 0.020*\"handle\"'),\n",
       " (95,\n",
       "  '0.071*\"are\" + 0.065*\"of\" + 0.060*\"for\" + 0.055*\"companies\" + 0.044*\"known\" + 0.042*\"main\" + 0.029*\"services\" + 0.029*\"rate\" + 0.029*\"brain\" + 0.026*\"oil\"'),\n",
       " (96,\n",
       "  '0.127*\"more\" + 0.114*\"than\" + 0.077*\"better\" + 0.062*\"or\" + 0.034*\"why\" + 0.032*\"are\" + 0.028*\"which\" + 0.024*\"less\" + 0.019*\"and\" + 0.019*\"pakistan\"'),\n",
       " (97,\n",
       "  '0.100*\"of\" + 0.057*\"in\" + 0.057*\"2\" + 0.042*\"1\" + 0.033*\"how\" + 0.030*\"affect\" + 0.028*\"reason\" + 0.026*\"safe\" + 0.024*\"education\" + 0.023*\"behind\"'),\n",
       " (98,\n",
       "  '0.097*\"quora\" + 0.057*\"on\" + 0.048*\"questions\" + 0.038*\"why\" + 0.038*\"future\" + 0.029*\"to\" + 0.025*\"others\" + 0.023*\"are\" + 0.019*\"answers\" + 0.018*\"of\"'),\n",
       " (99,\n",
       "  '0.080*\"real\" + 0.049*\"in\" + 0.039*\"full\" + 0.031*\"are\" + 0.028*\"news\" + 0.027*\"middle\" + 0.026*\"of\" + 0.023*\"fake\" + 0.021*\"film\" + 0.020*\"religious\"')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
