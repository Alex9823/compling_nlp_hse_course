{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Коллокации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллокации - это устойчивые выражения, состоящие из двух и более слов. Устойчивые - значит, что они часто используются вместе. Также часто значения коллокации не могут быть выведены лишь из значений, входящих в них слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение коллокаций на практике - это какая-то фильтрация нграммов в корпусе. Прежде чем, переходить к этому, вспомним как в питоне можно вытащить нграммы. Заодно повторим и нормализацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем какой-нибудь кусочек текста для примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Доклад Андрея можно использовать как справочник и how-to по отладке проблем с утечкой нативной памяти на примере non-heap памяти. \n",
    "\n",
    "Доклад полезен для понимания, кто и что съедает память. Андрей показывает инструменты для анализа памяти, в том числе AsyncProfiler, который встроен в Idea: «The upcoming IntelliJ IDEA 2018.3 integrates a low overhead sampling profiler that can profile JVM and Native code – Async profiler».\n",
    "\n",
    "Мы рекомендуем всем посмотреть его и прогнать по тем же шагам свои модули и микросервисы.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание. \n",
    "\n",
    "Напишите функцию, которая будет принимать текст, разбивать его на токены и группировать токены в нграммы. Параметр N - должен быть задаваемым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from string import punctuation\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [morph.parse(word.strip(punctuation))[0].normal_form for word \\\n",
    "                                                            in text.lower().split()]\n",
    "    normalized_text = [word for word in normalized_text if word]\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def ngrammer(tokens, n=2):\n",
    "    ## ваш код здесь\n",
    "    \n",
    "    return ngrams\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('доклад', 'андрей'),\n",
       " ('андрей', 'можно'),\n",
       " ('можно', 'использовать'),\n",
       " ('использовать', 'как'),\n",
       " ('как', 'справочник'),\n",
       " ('справочник', 'и'),\n",
       " ('и', 'how-to'),\n",
       " ('how-to', 'по'),\n",
       " ('по', 'отладка'),\n",
       " ('отладка', 'проблема')]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# работать должно вот так\n",
    "ngrammer(normalize(text))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдем к самим коллокациям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём небольшую коллекцию научных статей с киберленинки. Они переведены в текст с помощью pdf2text, поэтому там полно всякого мусора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = ['../data/'+file for file in os.listdir('../data')  if 'ng' in file and file.endswith('.jsonlines')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/ng_0.jsonlines']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pd.read_json(file, lines=True) for file in data_files[:2]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Многие интересуются, зачем нужна «Яблоку» молодежная фракция? Основной задачей «Молодежного «Яблока» является привлечение молодых людей к участию в выборах и деятельности партии. «Молодежное «Яблоко» работает более чем в 10 регионах. Единого руководства у нас нет, но мы стараемся координировать свою деятельность и периодически проводим акции на федеральном уровне.\\nМы ведем борьбу с обязательным воинским призывом. Военный – это профессия, а не обязанность. Молодые люди вправе сами распоряжаться своей жизнью и не терять целый год, отдавая государству «долг», который они у него не занимали. По мнению одного из ведущих специалистов в области оборонной политики Алексея Арбатова, переход на контрактную армию будет стоить лишь 2% военного бюджета.\\nТакже на федеральном уровне «Молодежное «Яблоко» проводило акции за освобождение политзаключенных и против вмешательства России во внутреннюю политику Украины.\\nРасскажу о московских активистах. Виктору Петрунину – 19 лет, он пришел к нам боль...</td>\n",
       "      <td>[яблоко, молодежь, молодежное яблоко]</td>\n",
       "      <td></td>\n",
       "      <td>\"Молодежное \"Яблоко\": оппозиционная деятельность становится опасной</td>\n",
       "      <td>http://www.ng.ru/ng_politics/2017-04-18/11_6976_apple.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   content  \\\n",
       "0  Многие интересуются, зачем нужна «Яблоку» молодежная фракция? Основной задачей «Молодежного «Яблока» является привлечение молодых людей к участию в выборах и деятельности партии. «Молодежное «Яблоко» работает более чем в 10 регионах. Единого руководства у нас нет, но мы стараемся координировать свою деятельность и периодически проводим акции на федеральном уровне.\\nМы ведем борьбу с обязательным воинским призывом. Военный – это профессия, а не обязанность. Молодые люди вправе сами распоряжаться своей жизнью и не терять целый год, отдавая государству «долг», который они у него не занимали. По мнению одного из ведущих специалистов в области оборонной политики Алексея Арбатова, переход на контрактную армию будет стоить лишь 2% военного бюджета.\\nТакже на федеральном уровне «Молодежное «Яблоко» проводило акции за освобождение политзаключенных и против вмешательства России во внутреннюю политику Украины.\\nРасскажу о московских активистах. Виктору Петрунину – 19 лет, он пришел к нам боль...   \n",
       "\n",
       "                                keywords summary  \\\n",
       "0  [яблоко, молодежь, молодежное яблоко]           \n",
       "\n",
       "                                                                 title  \\\n",
       "0  \"Молодежное \"Яблоко\": оппозиционная деятельность становится опасной   \n",
       "\n",
       "                                                          url  \n",
       "0  http://www.ng.ru/ng_politics/2017-04-18/11_6976_apple.html  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем тексты в токены с помощью функции, которую написали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['content'].apply(normalize).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('вчера', '«газпром»'),\n",
       " ('«газпром»', 'снизить'),\n",
       " ('снизить', 'верхний'),\n",
       " ('верхний', 'планка'),\n",
       " ('планка', 'прогноз'),\n",
       " ('прогноз', 'собственный'),\n",
       " ('собственный', 'добыча'),\n",
       " ('добыча', 'газа'),\n",
       " ('газа', 'в'),\n",
       " ('в', '2020'),\n",
       " ('2020', 'год'),\n",
       " ('год', 'через'),\n",
       " ('через', '12'),\n",
       " ('12', 'год'),\n",
       " ('год', 'концерн'),\n",
       " ('концерн', 'собираться'),\n",
       " ('собираться', 'добывать'),\n",
       " ('добывать', 'около'),\n",
       " ('около', '620–640'),\n",
       " ('620–640', 'миллиард')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrammer(texts[1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ найти устойчивые сочетания - просто посчитать всё и взять самые частотные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter()\n",
    "\n",
    "for text in texts:\n",
    "    word_counter.update(ngrammer(text, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('в', 'тот', 'число', 'и'), 100),\n",
       " (('в', 'то', 'же', 'время'), 100),\n",
       " (('дело', 'в', 'тот', 'что'), 51),\n",
       " (('несмотря', 'на', 'то', 'что'), 48),\n",
       " (('в', 'связь', 'с', 'это'), 45),\n",
       " (('в', 'то', 'время', 'как'), 40),\n",
       " (('миллиард', 'куб', 'метр', 'газа'), 40),\n",
       " (('до', 'сей', 'пора', 'не'), 36),\n",
       " (('говорить', 'о', 'тот', 'что'), 29),\n",
       " (('абхазия', 'и', 'южный', 'осетия'), 28),\n",
       " (('президент', 'рф', 'владимир', 'путин'), 27),\n",
       " (('в', 'тот', 'число', 'в'), 27),\n",
       " (('не', 'говорить', 'уже', 'о'), 24),\n",
       " (('состоять', 'в', 'тот', 'что'), 24),\n",
       " (('заключаться', 'в', 'тот', 'что'), 23)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В списке много всяких чисел, однобуквеных слов и стоп-слов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим какие-нибудь ограничения к коду выше, чтобы биграммы получались почище."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrammer(tokens, n=2, stops=set()):\n",
    "    \n",
    "#     tokens = normalize(text)\n",
    "    tokens = [token for token in tokens if token not in stops]\n",
    "    ngrams = list(zip(*(itertools.islice(tokens, i, None) for i in range(n))))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter()\n",
    "\n",
    "for text in texts:\n",
    "    word_counter.update(ngrammer(text, n=2, stops=stops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('–', 'это'), 778),\n",
       " (('2017', 'год'), 328),\n",
       " (('2016', 'год'), 274),\n",
       " (('–', 'сказать'), 221),\n",
       " (('владимир', 'путин'), 217),\n",
       " (('прошлое', 'год'), 211),\n",
       " (('миллиард', 'доллар'), 195),\n",
       " (('куб', 'метр'), 183),\n",
       " (('точка', 'зрение'), 178),\n",
       " (('это', 'год'), 171),\n",
       " (('год', 'назад'), 166),\n",
       " (('сей', 'пора'), 166),\n",
       " (('речь', 'идти'), 161),\n",
       " (('2015', 'год'), 151),\n",
       " (('весь', 'это'), 150)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В списке есть коллокации, которые попали в список из-за того, что одно слово очень частотное и вообще встречается много в каких контекстах. Нас скорее интересуют случаи, когда слова в большинстве случаев встречаются вместе. Для этого мы можем придумать какие-нибудь формулы, учитывающие частоты слов по отдельности и общую частоту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ - взять количество упоминаний биграма и поделить на сумму количеств упоминаний слов по отдельности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_simple(word_count_a, word_count_b, bigram_count, _):\n",
    "    try:\n",
    "        score = bigram_count/((word_count_a+word_count_b)-bigram_count)\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем функцию, которая будет делать счетчики для слов и биграммов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(texts):\n",
    "    ## соберем статистики для отдельных слов\n",
    "    ## и биграммов\n",
    "    \n",
    "    word_counter = Counter()\n",
    "    bigram_counter = Counter()\n",
    "    \n",
    "    for text in texts:\n",
    "        word_counter.update(text)\n",
    "        bigram_counter.update(ngrammer(text, 2, stops))\n",
    "    \n",
    "    return word_counter, bigram_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И функцию, которая пройдет по всем биграммам и вычислит для них нашу метрку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bigrams(word_counter, bigram_counter, scorer, threshold=-100000):\n",
    "    ## посчитаем метрику для каждого нграмма\n",
    "    bigram2score = Counter()\n",
    "    len_vocab = len(word_counter)\n",
    "    for bigram in bigram_counter:\n",
    "        score = scorer(word_counter[bigram[0]], word_counter[bigram[1]], \n",
    "                       bigram_counter[bigram], len_vocab)\n",
    "        \n",
    "        ## если метрика выше порога, добавляем в словарик\n",
    "        if score > threshold:\n",
    "            bigram2score[bigram] = score\n",
    "    \n",
    "    return bigram2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter, bigram_counter = collect_stats(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема с таким подходом в том, что на самом верху окажутся слова, которые встречают по одному разу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('н036', '«белка»'), 1.0),\n",
       " (('«three', 'zero»'), 1.0),\n",
       " (('цесаревич', 'цесаревна'), 1.0),\n",
       " (('метареализм', 'семиотика'), 1.0),\n",
       " (('rahmstorf', 'потсдамский'), 1.0),\n",
       " (('замесить', 'пресмыкание'), 1.0),\n",
       " (('виснуть', 'парусина'), 1.0),\n",
       " (('near', 'infrared'), 1.0),\n",
       " (('«империалистический', 'происки»'), 1.0),\n",
       " (('свирск', 'черемхово'), 1.0),\n",
       " (('золя', 'эдмона'), 1.0),\n",
       " (('розвальни', 'кочка'), 1.0),\n",
       " (('эльдар', 'рязанов'), 1.0),\n",
       " (('gaffney', 'cline&associates'), 1.0),\n",
       " (('water', 'congress'), 1.0)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому можно немного переделать оценивающую функцию, добавив минимальное число вхождений для биграмма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(word_count_a, word_count_b, bigram_count, _, minimum_count=10):\n",
    "    try:\n",
    "        score = ((bigram_count - minimum_count) / ((word_count_a + word_count_b) - bigram_count))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('саудовский', 'аравия'), 0.7111111111111111),\n",
       " (('red', 'bull'), 0.7027027027027027),\n",
       " (('бенедикт', 'xvi'), 0.6285714285714286),\n",
       " (('сей', 'пора'), 0.5591397849462365),\n",
       " (('точка', 'зрение'), 0.5419354838709678),\n",
       " (('toro', 'roso'), 0.5),\n",
       " (('чеченец', 'ингуш'), 0.41379310344827586),\n",
       " (('искусственный', 'интеллект'), 0.40869565217391307),\n",
       " (('homo', 'sapiens'), 0.3888888888888889),\n",
       " (('куб', 'метр'), 0.3581780538302277),\n",
       " (('кольцевой', 'автогонки'), 0.35),\n",
       " (('new', 'york'), 0.3333333333333333),\n",
       " (('гарф.ф', '6991'), 0.3125),\n",
       " (('нико', 'росберг'), 0.3108108108108108),\n",
       " (('washington', 'post'), 0.30434782608695654)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В статье про Word2Vec для создания нграммов использовалась такая функция:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(word_count_a, word_count_b, bigram_count,len_vocab, minimum_count=10):\n",
    "\n",
    "    try:\n",
    "        score = ((bigram_count - minimum_count) / (word_count_a * word_count_b)) * len_vocab\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, отличается ли она от нашей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('toro', 'roso'), 1302.025),\n",
       " (('homo', 'sapiens'), 1191.3954248366013),\n",
       " (('new', 'york'), 1157.3555555555556),\n",
       " (('гарф.ф', '6991'), 1085.0208333333333),\n",
       " (('кольцевой', 'автогонки'), 1065.985380116959),\n",
       " (('бенедикт', 'xvi'), 1021.1960784313725),\n",
       " (('red', 'bull'), 1016.5960960960962),\n",
       " (('чеченец', 'ингуш'), 979.5799373040753),\n",
       " (('washington', 'post'), 932.3964194373401),\n",
       " (('«войско', 'оон»'), 797.1581632653061),\n",
       " (('dragon', 'eye'), 759.5145833333333),\n",
       " (('вальттери', 'боттас'), 754.7971014492754),\n",
       " (('умберто', 'эко'), 649.8520499108735),\n",
       " (('тереза', 'мэй'), 642.9753086419753),\n",
       " (('ренэ', 'герр'), 642.9753086419753)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Популярная метрика для коллокация - PMI. Она очень похожа на то, что мы уже написали."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только вместо количества вохождений используют частотность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_pmi(word_count_a, word_count_b, bigram_count, _, corpus_size, minimum_count=5):\n",
    "    score = ((bigram_count/corpus_size) / ((word_count_a/corpus_size) * (word_count_b/corpus_size)))\n",
    "    \n",
    "    return np.log(score) / -np.log((bigram_count/corpus_size))\n",
    "\n",
    "def score_bigrams(word_counter, bigram_counter, scorer, threshold=-100000):\n",
    "    ## посчитаем метрику для каждого нграмма\n",
    "    bigram2score = Counter()\n",
    "    len_vocab = len(word_counter)\n",
    "    corpus_size = sum(word_counter.values())\n",
    "    \n",
    "    for bigram in bigram_counter:\n",
    "        score = scorer(word_counter[bigram[0]], word_counter[bigram[1]], \n",
    "                       bigram_counter[bigram], len_vocab, corpus_size)\n",
    "        \n",
    "        ## если метрика выше порога, добавляем в словарик\n",
    "        if score > threshold:\n",
    "            bigram2score[bigram] = score\n",
    "    \n",
    "    return bigram2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('н036', '«белка»'), 1.0),\n",
       " (('«three', 'zero»'), 1.0),\n",
       " (('цесаревич', 'цесаревна'), 1.0),\n",
       " (('метареализм', 'семиотика'), 1.0),\n",
       " (('rahmstorf', 'потсдамский'), 1.0),\n",
       " (('замесить', 'пресмыкание'), 1.0),\n",
       " (('виснуть', 'парусина'), 1.0),\n",
       " (('near', 'infrared'), 1.0),\n",
       " (('«империалистический', 'происки»'), 1.0),\n",
       " (('свирск', 'черемхово'), 1.0),\n",
       " (('золя', 'эдмона'), 1.0),\n",
       " (('розвальни', 'кочка'), 1.0),\n",
       " (('эльдар', 'рязанов'), 1.0),\n",
       " (('gaffney', 'cline&associates'), 1.0),\n",
       " (('water', 'congress'), 1.0)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё для оценки нграммов используют статистические тесты. Например, ttest выражается в частотах слов вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_ttest(word_count_a, word_count_b, bigram_count, _, corpus_size, minimum_count=5):\n",
    "    mu = ((word_count_a/corpus_size) * (word_count_b/corpus_size))\n",
    "    x_ = (bigram_count/corpus_size)\n",
    "    score = (x_ - mu) / np.sqrt(x_/corpus_size)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('–', 'это'), 24.609137170357467),\n",
       " (('2017', 'год'), 17.970580269597036),\n",
       " (('2016', 'год'), 16.436696795603797),\n",
       " (('владимир', 'путин'), 14.710647284146532),\n",
       " (('прошлое', 'год'), 14.366229586134002),\n",
       " (('–', 'сказать'), 13.961663861479058),\n",
       " (('миллиард', 'доллар'), 13.941389113195168),\n",
       " (('куб', 'метр'), 13.519292320540593),\n",
       " (('точка', 'зрение'), 13.33648192767963),\n",
       " (('сей', 'пора'), 12.879710463131945),\n",
       " (('год', 'назад'), 12.761195104210106),\n",
       " (('речь', 'идти'), 12.668439331475213),\n",
       " (('2015', 'год'), 12.201752933666516),\n",
       " (('2018', 'год'), 11.901448689899807),\n",
       " (('2014', 'год'), 11.708786199682178)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во всех случаях выше мы считали нграммами только слова, которые встречаются друг за другом. Но в нграммы часто можно ещё что-то вставить. Например, \"принять участие\" может превратиться в \"принять самое активное/непосредственное участие\". \n",
    "\n",
    "Чтобы отловить такие случаи можно считать нграммами слова, которые встречаются внутри какого-то окна. И считать по ним все те же метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ещё посчитать стандартное отклонение расстояния между двумя словами. Если оно маленькое - слова обычно стоят на строгой позиции по отношению друг к другу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_stats(texts, window=8):\n",
    "    \n",
    "    bigrams = defaultdict(list)\n",
    "    \n",
    "    # проходим окном по текстам \n",
    "    # берем первое слово и считаем его целевым\n",
    "    # проходим по остальным словам и их индексам\n",
    "    # добавляем в словарь пары (целевое слов, текущее слово)\n",
    "    # и добавляем индекс текущего в список этой пары\n",
    "    # так мы получаем (слово_1,слово_2):[1,2,1,1,3,2]\n",
    "    # порядок в этом случае учитывается - (слово_2, слово_1) - другая запись\n",
    "    for text in texts:\n",
    "        for i in range(len(text)-window):\n",
    "            words = list(enumerate(text[i:i+window]))\n",
    "            target = words[0][1]\n",
    "            for j, word in words[1:]:\n",
    "                bigrams[(target, word)].append(j)\n",
    "    \n",
    "    bigrams_stds = Counter()\n",
    "    for bigram in bigrams:\n",
    "        # выкидываем биграмы встретившиеся < 5 раз\n",
    "        if len(bigrams[bigram]) > 5:\n",
    "            bigrams_stds[bigram] = np.std(bigrams[bigram])\n",
    "    \n",
    "    return bigrams_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2std = get_window_stats(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('театр', 'твд'), 0.0),\n",
       " (('избавиться', 'от'), 0.0),\n",
       " (('власть', 'великобритания'), 0.0),\n",
       " (('en', 'group'), 0.0),\n",
       " (('много', 'ни'), 0.0),\n",
       " (('бутерброд', 'с'), 0.0),\n",
       " (('предвыборный', 'гонка'), 0.0),\n",
       " (('дмитрий', 'песок'), 0.0),\n",
       " (('бурят-монгольский', 'поэзия'), 0.0)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2std.most_common()[:-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно применять расширить размер нграмма, а можно последовательно преобразовывать один и тот же текст, на каждом шагу собирая новые биграммы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишием такую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_text(text, bigram2score):\n",
    "    new_text = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < (len(text)-1):\n",
    "        bigram = (text[i], text[i+1])\n",
    "        if bigram in bigram2score:\n",
    "            new_text.append('_'.join(bigram))\n",
    "            i += 2\n",
    "        else:\n",
    "            new_text.append(text[i])\n",
    "            i += 1\n",
    "    else:\n",
    "        if i == (len(text)-1):\n",
    "            new_text.append(text[i])\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_texts = [bigram_text(texts[i], bigram2score) for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_count, trigram_count = collect_stats(bi_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram2score = score_bigrams(bigram_count, trigram_count, scorer_ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_texts = [bigram_text(bi_texts[i], trigram2score) for i in range(len(bi_texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['вчера_«газпром»_снизить_верхний',\n",
       " 'планка_прогноз_собственный_добыча',\n",
       " 'газа',\n",
       " 'в',\n",
       " '2020_год',\n",
       " 'через',\n",
       " '12_год_концерн_собираться',\n",
       " 'добывать_около_620–640_миллиард',\n",
       " 'куб_метр',\n",
       " 'в']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_texts[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сюда тоже можно добавить окно и использовать метрику со стандартным отклонением посчтитанную выше. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По этой ссылке можно прочитать про другие метрики.\n",
    "\n",
    "http://www.scielo.org.mx/scielo.php?script=sci_arttext&pid=S1405-55462016000300327#t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все готовое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Писать все это самому конечно не обязательно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удобно пользоваться phraser из gensim'а. Он собирает статистику по корпусу, а затем склеивает слова в биграммы. Так как мы сделали выше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем статистики\n",
    "ph = gensim.models.Phrases(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразовывать можно и через ph, но так быстрее \n",
    "p = gensim.models.phrases.Phraser(ph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию там используется метрики из статьи про ворд2век и ещё есть нормализованные pmi.\n",
    "Если не нравятся функции оценки, то ему можно подать любую другую функцию. Интерфейс у функции там почти точно такой же как и у наших."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "?gensim.models.Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем статистики по уже забиграммленному тексту\n",
    "ph2 = gensim.models.Phrases(p[texts])\n",
    "p2 = gensim.models.phrases.Phraser(ph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['многие',\n",
       " 'интересоваться',\n",
       " 'зачем',\n",
       " 'нужный',\n",
       " '«яблоку»',\n",
       " 'молодёжный',\n",
       " 'фракция',\n",
       " 'основной_задача',\n",
       " '«молодёжный',\n",
       " '«яблока»',\n",
       " 'являться',\n",
       " 'привлечение',\n",
       " 'молодая_человек',\n",
       " 'к',\n",
       " 'участие',\n",
       " 'в',\n",
       " 'выборы',\n",
       " 'и',\n",
       " 'деятельность',\n",
       " 'партия']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2[p[texts[0]]][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и наконец нграммы есть в нлтк. Тут больше метрик, но преборазователь слов в нграммы нужно написать самому."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2 = BigramCollocationFinder.from_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder3 = TrigramCollocationFinder.from_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('один', 'из'),\n",
       " ('тот', 'что'),\n",
       " ('а', 'также'),\n",
       " ('при', 'это'),\n",
       " ('2017', 'год'),\n",
       " ('не', 'только'),\n",
       " ('точка', 'зрение'),\n",
       " ('то', 'есть'),\n",
       " ('сей', 'пора'),\n",
       " ('тот', 'число'),\n",
       " ('куб', 'метр'),\n",
       " ('владимир', 'путин'),\n",
       " ('2016', 'год'),\n",
       " ('тот', 'же'),\n",
       " ('потому', 'что'),\n",
       " ('миллиард', 'доллар'),\n",
       " ('о', 'тот'),\n",
       " ('прежде', 'всего'),\n",
       " ('кроме', 'тот'),\n",
       " ('до', 'сей')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder2.nbest(bigram_measures.likelihood_ratio, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1947–2001»', 'monterey', 'ca'),\n",
       " ('50-летие', 'rolling', 'stones'),\n",
       " ('acs', 'nano', 'letters'),\n",
       " ('areva', 'edf', 'alstom'),\n",
       " ('armored', 'multi-purpose', 'vehicles'),\n",
       " ('atr', 'ленур', 'ислям'),\n",
       " ('bad', 'can', 'it'),\n",
       " ('bourgeois', '«эпатировать', 'буржуа»'),\n",
       " ('bundesanstalt', 'fuer', 'geowissenschaften'),\n",
       " ('can', 'it', 'be'),\n",
       " ('charge', 'ion', 'battery'),\n",
       " ('citizens', '1947–2001»', 'monterey'),\n",
       " ('commitment', 'competence', 'consensus'),\n",
       " ('corriere', 'della', 'sera'),\n",
       " ('della', 'sera', 'папа-на-покой'),\n",
       " ('diyanet', 'isleri', 'turk-islam'),\n",
       " ('dux', 'recording', 'producers'),\n",
       " ('edf', 'alstom', 'schneider'),\n",
       " ('egf', 'gazprom', 'monitor'),\n",
       " ('espanola', 'чть', 'прад')]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder3.nbest(trigram_measures.pmi, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
