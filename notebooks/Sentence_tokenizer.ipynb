{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение текста на предложения (Определение границ предложений)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Текст в стандартной форме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в тексте есть знаки препинания, соблюдается регистр и мало ошибок -  найти границы предложений для большинства случаев будет достаточно просто. Большинство предложений заканчиваются на точку, вопросительный или восклицательные знаки, после которых идет какой-то отступ и другое слово с заглавной буквы. \n",
    "\n",
    "Да иногда будут попадаться аббревиатуры и сокращения или случаи, когда пробела после точки не стоит, но для задач, где не нужна точность - это не будет сильной проблемой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В nltk есть такая функция. Так как в русском и английском знаки препинания по большей части одинаковые - можно смело ей пользоваться прямо из коробки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files= ['../data/'+file for file in os.listdir('../data')]\n",
    "data = pd.concat([pd.read_json(file, lines=True) for file in files], axis=0, ignore_index=True)['content'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера возьмем совсем немного текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Многие интересуются, зачем нужна «Яблоку» молодежная фракция?',\n",
       " 'Основной задачей «Молодежного «Яблока» является привлечение молодых людей к участию в выборах и деятельности партии.',\n",
       " '«Молодежное «Яблоко» работает более чем в 10 регионах.',\n",
       " 'Единого руководства у нас нет, но мы стараемся координировать свою деятельность и периодически проводим акции на федеральном уровне.',\n",
       " 'Мы ведем борьбу с обязательным воинским призывом.',\n",
       " 'Военный – это профессия, а не обязанность.',\n",
       " 'Молодые люди вправе сами распоряжаться своей жизнью и не терять целый год, отдавая государству «долг», который они у него не занимали.',\n",
       " 'По мнению одного из ведущих специалистов в области оборонной политики Алексея Арбатова, переход на контрактную армию будет стоить лишь 2% военного бюджета.',\n",
       " 'Также на федеральном уровне «Молодежное «Яблоко» проводило акции за освобождение политзаключенных и против вмешательства России во внутреннюю политику Украины.',\n",
       " 'Расскажу о московских активистах.',\n",
       " 'Виктору Петрунину – 19 лет, он пришел к нам больше чем полтора года назад, когда только переехал в Москву.',\n",
       " 'Вся его семья придерживается демократических взглядов, а Виктора с раннего детства интересовала политика.',\n",
       " 'Виктор всегда очень критически относился к власти, но после Крыма, войны в Украине и убийства Бориса Немцова понял, что не может оставаться в стороне.',\n",
       " 'Заканчивая школу, он решил для себя, что должен присоединиться к близкой ему идеологически силе и добиваться смены власти в России.',\n",
       " '17-летняя Дарья Новичкова рассказывает, что огромное влияние на нее оказал ее преподаватель по обществознанию, который всегда трезво оценивал политическую ситуацию в стране.',\n",
       " 'Его искренность и неподдельная заинтересованность во многих злободневных вопросах помогли Дарье научиться фильтровать материал, который публикуется в различных СМИ.',\n",
       " 'Через некоторое время она поняла, что пассивное наблюдение за всем происходящим – самая невыгодная позиция из всех возможных, а потому необходимо каким-то образом действовать, лучше всего в команде единомышленников.',\n",
       " 'Затем, вдохновившись примером своего ровесника, который рассказал Дарье про «Молодежное «Яблоко», она решила к нам вступить.',\n",
       " 'В московском «Молодежном «Яблоке» действует дискуссионный клуб, в рамках него проходят лекции и кинопоказы на самые разные темы – от наступления консерватизма, обсуждения социально-либеральной альтернативы до ситуации в российской экономике.',\n",
       " 'Недавно один из участников круглого стола сказал нам, что никогда не присутствовал на мероприятиях, где имеет место столь открытая дискуссия, в которой может принять участие любой гость.',\n",
       " 'Петербургское «Молодежное «Яблоко» серьезно работает по городской повестке.',\n",
       " 'А в ноябре прошлого года они отправились в Карелию, чтобы провести акцию за свободу Ильдара Дадина рядом с колонией, где он тогда содержался, за что были задержаны, а судебный процесс по административному правонарушению, в котором обвинили активистов, до сих пор не завершился.',\n",
       " 'Ставропольцы недавно провели акции против декриминализации домашнего насилия, фотографии которой облетели Интернет.',\n",
       " '8 марта они организовали театрализованную акцию, чтобы напомнить, что этот «праздник» изначально появился как день борьбы за права женщин, но сегодня в России это пародия на его истинный смысл – женщин поздравляют с тем, что они «украшение» и «слабый пол».',\n",
       " 'Североосетинское отделение выступает против деятельности завода «Электроцинк», который наносит тяжелый ущерб окружающей среде.',\n",
       " 'Мы участвуем и в общепартийных мероприятиях, становимся кандидатами на выборах различного уровня.',\n",
       " 'В 2018 году наши активисты намерены участвовать в главной предвыборной кампании страны – выборах президента.',\n",
       " 'У «Яблока» есть свой кандидат – основатель партии Григорий Явлинский.',\n",
       " 'Его последовательность и неготовность разменивать принципы на проценты заслуживают уважения и поддержки.',\n",
       " 'Есть и проблемы.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.sub('[\\n\\t]', ' ', x) for x in sent_tokenize(data[0])[:30]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ни одной ошибки!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если уточнить разбиения все-таки нужно, есть способ обучить токенизатор на имеющихся текстах или даже добавить туда спорные случаи вручную.\n",
    "\n",
    "Про то как алгоритм обучается можно почитать тут  - \n",
    "В двух словах: считаются частотные аббревиатуры, которые потом не используются как разделители.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train('\\n'.join(data))\n",
    " \n",
    "tokenizer = PunktSentenceTokenizer(trainer.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список выученных сокращений можно достать вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'т.д', 'н.а', 'с.г', 'аэс', 'пер', 'кв', 'руб', 'куб', 'ю.н', 'пл', 'др', 'я»', 'д', 'н.к', 'м»', 'см', 'тыс', 'б', 'г', 'стр', 'долл', 's'}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer._params.abbrev_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы удобнее просматривать окончания можно отрезать все до последних 10 символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['е (Техас).',\n",
       " 'оехали 15.',\n",
       " 'ить заезд.',\n",
       " ' Росберга.',\n",
       " 'Риккъярдо.',\n",
       " 'е удалась.',\n",
       " 'це заезда.',\n",
       " ' досрочно.',\n",
       " ' Marussia.',\n",
       " ' Абу-Даби.',\n",
       " 'авершению.',\n",
       " 'ио Переса.',\n",
       " 'айкконена.',\n",
       " 'до боксов.',\n",
       " 'щей гонки.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.sub('[\\n\\t]', ' ', x)[-10:] for x in tokenizer.tokenize(data[5])[:15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и в него же напрямую можно что-то добавить (без учета регистра и без точки на конце)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно сразу добавить все числа и сокращения имен и отчеств\n",
    "tokenizer._params.abbrev_types.add('15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['е (Техас).',\n",
       " 'ить заезд.',\n",
       " ' Росберга.',\n",
       " 'Риккъярдо.',\n",
       " 'е удалась.',\n",
       " 'це заезда.',\n",
       " ' досрочно.',\n",
       " ' Marussia.',\n",
       " ' Абу-Даби.',\n",
       " 'авершению.',\n",
       " 'ио Переса.',\n",
       " 'айкконена.',\n",
       " 'до боксов.',\n",
       " 'щей гонки.',\n",
       " 'кий сход).']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.sub('[\\n\\t]', ' ', x)[-10:] for x in tokenizer.tokenize(data[5])[:15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После нескольких итераций ручной подкрутки может возникнуть желание более точно измерить качество разбиений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как это можно измерить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно взять какой-то текст и разбить его руками. А потом разбить этот ж текст моделью и сравнить длины полученных списков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = tokenizer.tokenize(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В Ленинском районном суде продолжаются слушания по делу экс-депутата Думы Владивостока Зинаиды Ким и бывшего председателя избирательного участка № 522 Елены Футиной, которых обвиняют в сговоре и фальсификациях результатов на выборах на сентябрьских выборах 2016 года.',\n",
       " 'Напомним, 18 сентября 2017 года местные журналисты сняли на видео, как Ким, будучи кандидатом по спискам в Законодательное Собрание Приморского края, выдавала молодым людям открепительные, возила их голосовать на участок, где уже знали о предстоящем визите.',\n",
       " 'В качестве вознаграждения избирателям предлагалось по 500 рублей.',\n",
       " 'Перед началом судебного процесса Зинаида Ким разговаривала с журналистами на повышенных тонах и обзывая, доказывала, что видео – монтаж.',\n",
       " 'Адвокаты представили вниманию участников процесса характеристику подсудимой, составленную руководителями Всероссийской общественной организации «Боевое братство (Приморье)», членом которого является подсудимая.',\n",
       " 'Выяснилось, что у Зинаиды Ким – богатый наградной список: есть, например, памятные знаки к 65 – и 70-летию Победы в Великой Отечественной войне, к 25-летию вывода советских войск из Афганистана, 20-летию МЧС и многие другие.',\n",
       " 'В ходе заседания адвокат Алексей Клецкин попросил судью назначить дополнительную комплексную экспертизу видео – и аудиозаписей, представленных в процессе в качестве основных доказательств вины Ким и Футиной, хотя прежде защитники не высказывали сомнений в подлинности экспертизы.',\n",
       " 'Государственный обвинитель прошение защитников назвал необоснованным, судья поддержал позицию представителя прокуратуры.',\n",
       " 'На предшествующих судебных заседаниях по делу Зинаиды Ким и Елены Футиной были допрошены свидетели – бывший главный редактор издания VL.RU Иван Федотов, бывший журналист Маргарита Бабченко.',\n",
       " 'Зинаида Ким заявила в суде, что журналист, выявивший противоправные действия, предлагал ей закрыть дело за вознаграждение в 500 000 рублей.',\n",
       " 'Иван Федотов объяснил ситуацию: он отправил на разговор вместо себя своего коллегу.',\n",
       " 'То, что она встречалась с другим сотрудником редакции, Зинаида Ким поняла только на судебном заседании.',\n",
       " 'Свидетель, внештатный видеограф информационного агентства Даниила Губарев, рассказал суду о работе на сайте, о своих профессиональных обязанностям.',\n",
       " 'Он подтвердил, что никаких манипуляций с видео на мобильном телефоне он не проводил.',\n",
       " 'На компьютере, из отснятых корреспондентами материалов, он смонтировал ролик: весь монтаж заключался в склейке фрагментов и наложении субтитров.',\n",
       " 'По словам свидетеля, в итоговом видео убрали только «грязные» кадры – то есть те, на которых ничего не происходит.',\n",
       " 'На экспертизу видеодоказательств и другие следственные процедуры понадобилось почти девять месяцев и пять депутатских запросов в СУ СК по Приморью.',\n",
       " 'За фальсификацию избирательных документов или документов референдума Ким грозит штраф в размере от 100 тыс. до 300 тыс. рублей или в размере заработной платы, или иного дохода за период до двух лет, либо принудительные работы на срок до четырех лет, либо лишение свободы на тот же срок.',\n",
       " 'Владивосток']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_split = sent_tokenize(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold length -  19\n",
      "My split -  21\n"
     ]
    }
   ],
   "source": [
    "print('Gold length - ', len(gold))\n",
    "print('My split - ', len(my_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понятно, что это не очень хороший способ (его можно обмануть), но что-то он покажет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно привести списки к множествам и посчитать пересечения - одинаковые предложения будут считать совпадающими элементами.\n",
    "\n",
    "Тут нужно быть аккуратным, так как модель может отрезать один лишний символ и это уже будет считать промахом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# добавим нормировку на длину объединения\n",
    "len(set(gold) & set(my_split)) / len(set(gold) | set(my_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нем использовалась такая метрика - берем идеальное предложение и пробуем разбить его нашей моделью - если  разбивается, считает этой ошибкой, если нет - правильным ответом. \n",
    "Потом берем два идеальных предложения - склеиваем их пробельным символом и пробуем разбить нашей моделью. Если разбивает на два нужных предложения - все правильно.\n",
    "\n",
    "Таким образом мы вычисляем tp fp fn для расчета точности, полноты и f1 меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.9714285714285714\n",
      "Recall -  0.9444444444444444\n",
      "F1 -  0.9577464788732395\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for sent in gold:\n",
    "    if len(sent_tokenize(sent)) == 1:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n",
    "for i in range(len(gold)-1):\n",
    "    sent1, sent2 = gold[i], gold[i+1]\n",
    "    sent = ' '.join([sent1, sent2])\n",
    "    if len(sent_tokenize(sent)) == 2:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "precision = (tp/(tp+fp))\n",
    "recall = (tp/(tp+fn))\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "print('Precision - ', precision)\n",
    "print('Recall - ', recall)\n",
    "print('F1 - ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такую метрики использовали авторы вот этого токенизатора для русского - https://github.com/deepmipt/ru_sentence_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно придумать и что-то посложнее. \n",
    "\n",
    "Перейдем к индексам символов в тексте. Теперь нам нужно для каждого символа предсказать является ли он разбивающим или нет. Потом можно применять стандартные метрики качества классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 267),\n",
       " (268, 525),\n",
       " (526, 591),\n",
       " (592, 728),\n",
       " (729, 939),\n",
       " (940, 1164),\n",
       " (1166, 1445),\n",
       " (1446, 1566),\n",
       " (1568, 1757),\n",
       " (1758, 1897),\n",
       " (1898, 1981),\n",
       " (1982, 2085),\n",
       " (2086, 2233),\n",
       " (2234, 2318),\n",
       " (2319, 2463),\n",
       " (2464, 2578),\n",
       " (2579, 2726),\n",
       " (2727, 3013),\n",
       " (3015, 3026)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.span_tokenize(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = [0 for i in range(len(data[3]))]\n",
    "for span in tokenizer.span_tokenize(data[3]):\n",
    "    gold[span[1]-1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokenize(data[3])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_split = [0 for i in range(len(data[3]))]\n",
    "index = 0\n",
    "for sent in sent_tokenize(data[3]):\n",
    "    index += len(sent)\n",
    "    my_split[index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3007\n",
      "           1       0.05      0.05      0.05        19\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3026\n",
      "   macro avg       0.52      0.52      0.52      3026\n",
      "weighted avg       0.99      0.99      0.99      3026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gold, my_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё можно выписать индексы всех разбивающих символов и рассматривать это как строку. Между двумя строками (идеальной и той, что выдала модель) можно посчитать edit distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editdistance.eval([1,2,3], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = []\n",
    "my_split = []\n",
    "for span in tokenizer.span_tokenize(data[3]):\n",
    "    gold.append(span[1])\n",
    "\n",
    "index = 0\n",
    "for sent in sent_tokenize(data[3]):\n",
    "    index += len(sent)\n",
    "    my_split.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editdistance.eval(gold, my_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот тут можно почитать про другие метрики (и их сравнение) - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.417.8097&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Нестандартный текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бывает, что текст приходит откуда-то ещё (например, с text2speech модуля) сплошняком без каких-либо знаков препинания и регистров. Либо в нём столько неточностей, что стандартные методы ошибаются на каждом втором слове (например, при переводе пдфа в текст)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае нужно как-то учитывать смысл написанного. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого хорошо подойдут рекурентные нейронные сети. \n",
    "\n",
    "Обучающую выборку собрать из обычных текстов, разделенных вручную или автоматически, убрав всю пунктуацию и привидя их к нижнему регистру. Ну или сделать то же самое с предложениями из какого-нибудь синтагруса.\n",
    "\n",
    "Саму задачу можно рассматривать как задачу классификации. К целым предложениям можно приписать положительный класс (т.е. после последнего слова нужно поставить разделитель), а для подбора отрицательного класса, можно нарезать предложения на части и каждой из них приписать отрицательный класс (т.е. разделителя не нужно). \n",
    "\n",
    "Например, предложение \"вчера кажется бы снег\" преборазуется в:\n",
    "\n",
    "\"вчера кажется был снег\" - 1\n",
    "\"вчера кажется был\" - 0\n",
    "\"кажется был\" - 0\n",
    "\"вчера кажется\" - 0\n",
    "\n",
    "Вообще можно и положительный класс пополнить таким методом (выбрость первое слово, например), но лучше этого не делать. Потому что предложения бывают разные и не всегда можно что-то обросить без потери смысла. Ну и в нулевой класс могут попасть нормальные предложения (был снег, например). Но можно предположиться, что такое будет случаться не часто."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем на небольшом количестве предложений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы ещё ничего не знаете про нейронные сети или знаете очень мало, не пугайтесь. Попробуйте запустить мой код и посмотреть, что он делает. Попробуйте что-то поменять и посмотреть что изменится. Ну и потом уже можете пойти почитать про то, как оно устроено. Такой top-down (от практики к теории) используют в fast.ai для обучения нейронным сетям и это работает! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "punct=punctuation+'«…»'\n",
    "def normalize(text):\n",
    "    tokens = [word.strip(punct) for word in text.lower().split()]\n",
    "    tokens = [word for word in tokens if word]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в',\n",
       " 'ленинском',\n",
       " 'районном',\n",
       " 'суде',\n",
       " 'продолжаются',\n",
       " 'слушания',\n",
       " 'по',\n",
       " 'делу',\n",
       " 'экс-депутата',\n",
       " 'думы']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(tokenizer.tokenize(data[3])[0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "files= ['../data/'+file for file in os.listdir('../data')]\n",
    "data = pd.concat([pd.read_json(file, lines=True) for file in files], axis=0, ignore_index=True)['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sents = []\n",
    "for text in data:\n",
    "    sents = [normalize(sent) for sent in tokenizer.tokenize(text)]\n",
    "    for sent in sents:\n",
    "        if sent:\n",
    "            good_sents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['многие',\n",
       "  'интересуются',\n",
       "  'зачем',\n",
       "  'нужна',\n",
       "  'яблоку',\n",
       "  'молодежная',\n",
       "  'фракция'],\n",
       " ['основной',\n",
       "  'задачей',\n",
       "  'молодежного',\n",
       "  'яблока',\n",
       "  'является',\n",
       "  'привлечение',\n",
       "  'молодых',\n",
       "  'людей',\n",
       "  'к',\n",
       "  'участию',\n",
       "  'в',\n",
       "  'выборах',\n",
       "  'и',\n",
       "  'деятельности',\n",
       "  'партии'],\n",
       " ['молодежное', 'яблоко', 'работает', 'более', 'чем', 'в', '10', 'регионах']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_sents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sents = []\n",
    "for sent in good_sents:\n",
    "    not_lust = sent[:-1]\n",
    "    while len(not_lust) >= 1:\n",
    "        bad_sents.append(not_lust)\n",
    "        not_lust = not_lust[:-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['многие', 'интересуются', 'зачем', 'нужна', 'яблоку', 'молодежная']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_sents[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['многие', 'интересуются', 'зачем', 'нужна', 'яблоку', 'молодежная'],\n",
       " ['многие', 'интересуются', 'зачем', 'нужна', 'яблоку'],\n",
       " ['многие', 'интересуются', 'зачем', 'нужна'],\n",
       " ['многие', 'интересуются', 'зачем']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_sents[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = good_sents + bad_sents\n",
    "target = [1 for i in range(len(good_sents))] + [0 for i in range(len(bad_sents))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for sent in sents:\n",
    "    vocab.update(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115476"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in vocab if vocab[x] > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i+2:word for i, word in enumerate(vocab) if vocab[word] > 5}\n",
    "word2id = {word:i for i, word in id2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_ids = []\n",
    "\n",
    "for sent in sents:\n",
    "    sents_ids.append([word2id.get(word, 1) for word in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[121807, 72419, 9446, 121910, 13972, 93117, 57408],\n",
       " [55686,\n",
       "  48638,\n",
       "  39945,\n",
       "  64042,\n",
       "  64798,\n",
       "  6283,\n",
       "  127413,\n",
       "  76882,\n",
       "  75188,\n",
       "  101669,\n",
       "  119564,\n",
       "  122090,\n",
       "  72083,\n",
       "  38215,\n",
       "  63033],\n",
       " [13539, 133997, 9931, 124643, 49538, 119564, 92041, 118780]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_ids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Embedding, Dense, Dropout, Bidirectional, CuDNNLSTM\n",
    "from keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sents_ids, 20, truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.098569722474977"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(s) for s in sents_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(vocab)+2, output_dim=32, input_length=maxlen))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(CuDNNLSTM(30)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1266048 samples, validate on 422016 samples\n",
      "Epoch 1/10\n",
      "1266048/1266048 [==============================] - 122s 96us/step - loss: 0.1687 - acc: 0.9427 - val_loss: 0.1519 - val_acc: 0.9441\n",
      "Epoch 2/10\n",
      "1266048/1266048 [==============================] - 117s 92us/step - loss: 0.1296 - acc: 0.9505 - val_loss: 0.1464 - val_acc: 0.9452\n",
      "Epoch 3/10\n",
      "1266048/1266048 [==============================] - 116s 92us/step - loss: 0.1060 - acc: 0.9601 - val_loss: 0.1467 - val_acc: 0.9465\n",
      "Epoch 4/10\n",
      "1266048/1266048 [==============================] - 116s 92us/step - loss: 0.0896 - acc: 0.9666 - val_loss: 0.1490 - val_acc: 0.9465\n",
      "Epoch 5/10\n",
      "1266048/1266048 [==============================] - 115s 91us/step - loss: 0.0778 - acc: 0.9714 - val_loss: 0.1570 - val_acc: 0.9488\n",
      "Epoch 6/10\n",
      "1266048/1266048 [==============================] - 116s 92us/step - loss: 0.0683 - acc: 0.9751 - val_loss: 0.1614 - val_acc: 0.9495\n",
      "Epoch 7/10\n",
      "1266048/1266048 [==============================] - 117s 93us/step - loss: 0.0613 - acc: 0.9777 - val_loss: 0.1696 - val_acc: 0.9498\n",
      "Epoch 8/10\n",
      " 962304/1266048 [=====================>........] - ETA: 27s - loss: 0.0540 - acc: 0.9807"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-993ad90d3d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_train, y_train, batch_size=128, epochs=10,\n\u001b[0;32m----> 2\u001b[0;31m           validation_data=[X_valid, y_valid])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь попробуем сделать предсказание этой моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "gold = tokenizer.tokenize(data[3])\n",
    "for sent in gold:\n",
    "    sample += normalize(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "sents = []\n",
    "for word in sample:\n",
    "#     if word not in word2id:\n",
    "#         continue\n",
    "    stack.append(word)\n",
    "    vec = [word2id.get(w, 1) for w in stack]\n",
    "    vec = pad_sequences([vec], maxlen)\n",
    "    pred = model.predict(vec)\n",
    "    if pred[0][0] > 0.6:\n",
    "        sents.append(stack)\n",
    "        stack = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['в',\n",
       "  'ленинском',\n",
       "  'районном',\n",
       "  'суде',\n",
       "  'продолжаются',\n",
       "  'слушания',\n",
       "  'по',\n",
       "  'делу',\n",
       "  'экс-депутата',\n",
       "  'думы',\n",
       "  'владивостока',\n",
       "  'зинаиды',\n",
       "  'ким',\n",
       "  'и',\n",
       "  'бывшего',\n",
       "  'председателя',\n",
       "  'избирательного',\n",
       "  'участка',\n",
       "  '№',\n",
       "  '522',\n",
       "  'елены',\n",
       "  'футиной',\n",
       "  'которых',\n",
       "  'обвиняют',\n",
       "  'в',\n",
       "  'сговоре',\n",
       "  'и',\n",
       "  'фальсификациях',\n",
       "  'результатов',\n",
       "  'на',\n",
       "  'выборах',\n",
       "  'на',\n",
       "  'сентябрьских',\n",
       "  'выборах',\n",
       "  '2016',\n",
       "  'года'],\n",
       " ['напомним',\n",
       "  '18',\n",
       "  'сентября',\n",
       "  '2017',\n",
       "  'года',\n",
       "  'местные',\n",
       "  'журналисты',\n",
       "  'сняли',\n",
       "  'на',\n",
       "  'видео',\n",
       "  'как',\n",
       "  'ким',\n",
       "  'будучи',\n",
       "  'кандидатом',\n",
       "  'по',\n",
       "  'спискам',\n",
       "  'в',\n",
       "  'законодательное',\n",
       "  'собрание',\n",
       "  'приморского',\n",
       "  'края',\n",
       "  'выдавала',\n",
       "  'молодым',\n",
       "  'людям',\n",
       "  'открепительные',\n",
       "  'возила',\n",
       "  'их',\n",
       "  'голосовать',\n",
       "  'на',\n",
       "  'участок',\n",
       "  'где',\n",
       "  'уже',\n",
       "  'знали',\n",
       "  'о',\n",
       "  'предстоящем',\n",
       "  'визите'],\n",
       " ['в',\n",
       "  'качестве',\n",
       "  'вознаграждения',\n",
       "  'избирателям',\n",
       "  'предлагалось',\n",
       "  'по',\n",
       "  '500',\n",
       "  'рублей',\n",
       "  'перед',\n",
       "  'началом',\n",
       "  'судебного',\n",
       "  'процесса',\n",
       "  'зинаида',\n",
       "  'ким',\n",
       "  'разговаривала',\n",
       "  'с',\n",
       "  'журналистами',\n",
       "  'на',\n",
       "  'повышенных',\n",
       "  'тонах',\n",
       "  'и',\n",
       "  'обзывая',\n",
       "  'доказывала',\n",
       "  'что',\n",
       "  'видео',\n",
       "  '–',\n",
       "  'монтаж',\n",
       "  'адвокаты'],\n",
       " ['представили',\n",
       "  'вниманию',\n",
       "  'участников',\n",
       "  'процесса',\n",
       "  'характеристику',\n",
       "  'подсудимой',\n",
       "  'составленную',\n",
       "  'руководителями',\n",
       "  'всероссийской',\n",
       "  'общественной',\n",
       "  'организации',\n",
       "  'боевое',\n",
       "  'братство',\n",
       "  'приморье',\n",
       "  'членом',\n",
       "  'которого',\n",
       "  'является',\n",
       "  'подсудимая',\n",
       "  'выяснилось'],\n",
       " ['что',\n",
       "  'у',\n",
       "  'зинаиды',\n",
       "  'ким',\n",
       "  '–',\n",
       "  'богатый',\n",
       "  'наградной',\n",
       "  'список',\n",
       "  'есть',\n",
       "  'например',\n",
       "  'памятные',\n",
       "  'знаки',\n",
       "  'к',\n",
       "  '65',\n",
       "  '–',\n",
       "  'и',\n",
       "  '70-летию',\n",
       "  'победы',\n",
       "  'в',\n",
       "  'великой',\n",
       "  'отечественной',\n",
       "  'войне',\n",
       "  'к',\n",
       "  '25-летию',\n",
       "  'вывода',\n",
       "  'советских',\n",
       "  'войск',\n",
       "  'из',\n",
       "  'афганистана',\n",
       "  '20-летию',\n",
       "  'мчс',\n",
       "  'и',\n",
       "  'многие',\n",
       "  'другие'],\n",
       " ['в',\n",
       "  'ходе',\n",
       "  'заседания',\n",
       "  'адвокат',\n",
       "  'алексей',\n",
       "  'клецкин',\n",
       "  'попросил',\n",
       "  'судью',\n",
       "  'назначить',\n",
       "  'дополнительную',\n",
       "  'комплексную',\n",
       "  'экспертизу',\n",
       "  'видео',\n",
       "  '–',\n",
       "  'и',\n",
       "  'аудиозаписей',\n",
       "  'представленных',\n",
       "  'в',\n",
       "  'процессе',\n",
       "  'в',\n",
       "  'качестве',\n",
       "  'основных',\n",
       "  'доказательств',\n",
       "  'вины',\n",
       "  'ким',\n",
       "  'и',\n",
       "  'футиной',\n",
       "  'хотя',\n",
       "  'прежде',\n",
       "  'защитники',\n",
       "  'не',\n",
       "  'высказывали',\n",
       "  'сомнений',\n",
       "  'в',\n",
       "  'подлинности',\n",
       "  'экспертизы',\n",
       "  'государственный',\n",
       "  'обвинитель',\n",
       "  'прошение',\n",
       "  'защитников',\n",
       "  'назвал',\n",
       "  'необоснованным',\n",
       "  'судья',\n",
       "  'поддержал',\n",
       "  'позицию',\n",
       "  'представителя',\n",
       "  'прокуратуры'],\n",
       " ['на',\n",
       "  'предшествующих',\n",
       "  'судебных',\n",
       "  'заседаниях',\n",
       "  'по',\n",
       "  'делу',\n",
       "  'зинаиды',\n",
       "  'ким',\n",
       "  'и',\n",
       "  'елены',\n",
       "  'футиной',\n",
       "  'были',\n",
       "  'допрошены',\n",
       "  'свидетели',\n",
       "  '–',\n",
       "  'бывший',\n",
       "  'главный',\n",
       "  'редактор',\n",
       "  'издания',\n",
       "  'vl.ru',\n",
       "  'иван',\n",
       "  'федотов',\n",
       "  'бывший',\n",
       "  'журналист',\n",
       "  'маргарита'],\n",
       " ['бабченко', 'зинаида', 'ким', 'заявила', 'в', 'суде'],\n",
       " ['что', 'журналист', 'выявивший', 'противоправные'],\n",
       " ['действия',\n",
       "  'предлагал',\n",
       "  'ей',\n",
       "  'закрыть',\n",
       "  'дело',\n",
       "  'за',\n",
       "  'вознаграждение',\n",
       "  'в',\n",
       "  '500',\n",
       "  '000',\n",
       "  'рублей'],\n",
       " ['иван',\n",
       "  'федотов',\n",
       "  'объяснил',\n",
       "  'ситуацию',\n",
       "  'он',\n",
       "  'отправил',\n",
       "  'на',\n",
       "  'разговор',\n",
       "  'вместо',\n",
       "  'себя',\n",
       "  'своего',\n",
       "  'коллегу'],\n",
       " ['то',\n",
       "  'что',\n",
       "  'она',\n",
       "  'встречалась',\n",
       "  'с',\n",
       "  'другим',\n",
       "  'сотрудником',\n",
       "  'редакции',\n",
       "  'зинаида',\n",
       "  'ким',\n",
       "  'поняла',\n",
       "  'только',\n",
       "  'на',\n",
       "  'судебном',\n",
       "  'заседании'],\n",
       " ['свидетель',\n",
       "  'внештатный',\n",
       "  'видеограф',\n",
       "  'информационного',\n",
       "  'агентства',\n",
       "  'даниила',\n",
       "  'губарев',\n",
       "  'рассказал',\n",
       "  'суду',\n",
       "  'о',\n",
       "  'работе',\n",
       "  'на',\n",
       "  'сайте',\n",
       "  'о',\n",
       "  'своих',\n",
       "  'профессиональных',\n",
       "  'обязанностям'],\n",
       " ['он',\n",
       "  'подтвердил',\n",
       "  'что',\n",
       "  'никаких',\n",
       "  'манипуляций',\n",
       "  'с',\n",
       "  'видео',\n",
       "  'на',\n",
       "  'мобильном',\n",
       "  'телефоне',\n",
       "  'он',\n",
       "  'не',\n",
       "  'проводил'],\n",
       " ['на',\n",
       "  'компьютере',\n",
       "  'из',\n",
       "  'отснятых',\n",
       "  'корреспондентами',\n",
       "  'материалов',\n",
       "  'он',\n",
       "  'смонтировал',\n",
       "  'ролик',\n",
       "  'весь',\n",
       "  'монтаж',\n",
       "  'заключался',\n",
       "  'в',\n",
       "  'склейке',\n",
       "  'фрагментов',\n",
       "  'и',\n",
       "  'наложении',\n",
       "  'субтитров'],\n",
       " ['по',\n",
       "  'словам',\n",
       "  'свидетеля',\n",
       "  'в',\n",
       "  'итоговом',\n",
       "  'видео',\n",
       "  'убрали',\n",
       "  'только',\n",
       "  'грязные',\n",
       "  'кадры',\n",
       "  '–',\n",
       "  'то',\n",
       "  'есть',\n",
       "  'те',\n",
       "  'на',\n",
       "  'которых',\n",
       "  'ничего',\n",
       "  'не',\n",
       "  'происходит'],\n",
       " ['на',\n",
       "  'экспертизу',\n",
       "  'видеодоказательств',\n",
       "  'и',\n",
       "  'другие',\n",
       "  'следственные',\n",
       "  'процедуры',\n",
       "  'понадобилось',\n",
       "  'почти',\n",
       "  'девять',\n",
       "  'месяцев',\n",
       "  'и',\n",
       "  'пять',\n",
       "  'депутатских',\n",
       "  'запросов',\n",
       "  'в',\n",
       "  'су',\n",
       "  'ск',\n",
       "  'по',\n",
       "  'приморью',\n",
       "  'за',\n",
       "  'фальсификацию'],\n",
       " ['избирательных',\n",
       "  'документов',\n",
       "  'или',\n",
       "  'документов',\n",
       "  'референдума',\n",
       "  'ким',\n",
       "  'грозит',\n",
       "  'штраф',\n",
       "  'в',\n",
       "  'размере',\n",
       "  'от',\n",
       "  '100',\n",
       "  'тыс',\n",
       "  'до',\n",
       "  '300',\n",
       "  'тыс',\n",
       "  'рублей'],\n",
       " ['или', 'в', 'размере', 'заработной', 'платы', 'или', 'иного', 'дохода'],\n",
       " ['за',\n",
       "  'период',\n",
       "  'до',\n",
       "  'двух',\n",
       "  'лет',\n",
       "  'либо',\n",
       "  'принудительные',\n",
       "  'работы',\n",
       "  'на',\n",
       "  'срок',\n",
       "  'до',\n",
       "  'четырех',\n",
       "  'лет',\n",
       "  'либо',\n",
       "  'лишение',\n",
       "  'свободы',\n",
       "  'на',\n",
       "  'тот',\n",
       "  'же',\n",
       "  'срок'],\n",
       " ['владивосток']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
