{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "morph = MorphAnalyzer()\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(PATH_TO_DATA, file) for file in os.listdir(PATH_TO_DATA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/ng_0.jsonlines.zip'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(files[0], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[яблоко, молодежь, молодежное яблоко]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[газпром, газ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[франсуа рабле, сервантес, шекспир, конан дойл, михаил булгаков, александр грин, борхес, босх, маркес, герман гессе, голландская живопись, гаргантюа и пантагрюэль, дон кихот, мастер и маргарита, москва, россия, история, поэзия, шотландия, баллада, пере]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[владивосток, суд, ким, футина, выборы, боевое братство]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[новая москва, подмосковье, благоустройство, тинао, городская среда, парки]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[автоспорт, формула1, гонки, хэмилтон, квят, сша]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ведущие политики, рейтинг, февраль]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[законы, культура, концепция, уголовные дела, платформа, аресты]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[сирия, вооруженный конфликт, газ, углеводороды, турецкий поток]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[фсб, иг, калужская область]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[проза, фантастика, поезд, стихи, переводы, химия, контрабанда, галлюцинации]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                         keywords\n",
       "0                                                                                                                                                                                                                           [яблоко, молодежь, молодежное яблоко]\n",
       "1                                                                                                                                                                                                                                                  [газпром, газ]\n",
       "2   [франсуа рабле, сервантес, шекспир, конан дойл, михаил булгаков, александр грин, борхес, босх, маркес, герман гессе, голландская живопись, гаргантюа и пантагрюэль, дон кихот, мастер и маргарита, москва, россия, история, поэзия, шотландия, баллада, пере]\n",
       "3                                                                                                                                                                                                        [владивосток, суд, ким, футина, выборы, боевое братство]\n",
       "4                                                                                                                                                                                     [новая москва, подмосковье, благоустройство, тинао, городская среда, парки]\n",
       "5                                                                                                                                                                                                               [автоспорт, формула1, гонки, хэмилтон, квят, сша]\n",
       "6                                                                                                                                                                                                                            [ведущие политики, рейтинг, февраль]\n",
       "7                                                                                                                                                                                                [законы, культура, концепция, уголовные дела, платформа, аресты]\n",
       "8                                                                                                                                                                                                [сирия, вооруженный конфликт, газ, углеводороды, турецкий поток]\n",
       "9                                                                                                                                                                                                                                    [фсб, иг, калужская область]\n",
       "10                                                                                                                                                                                  [проза, фантастика, поезд, стихи, переводы, химия, контрабанда, галлюцинации]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0:10, [\"keywords\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_kws, predicted_kws):\n",
    "    assert len(true_kws) == len(predicted_kws)\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    jaccards = []\n",
    "    \n",
    "    for i in range(len(true_kws)):\n",
    "        true_kw = set(true_kws[i])\n",
    "        predicted_kw = set(predicted_kws[i])\n",
    "        \n",
    "        tp = len(true_kw & predicted_kw)\n",
    "        union = len(true_kw | predicted_kw)\n",
    "        fp = len(predicted_kw - true_kw)\n",
    "        fn = len(true_kw - predicted_kw)\n",
    "        \n",
    "        if (tp+fp) == 0:\n",
    "            prec = 0\n",
    "        else:\n",
    "            prec = tp / (tp + fp)\n",
    "        \n",
    "        if (tp+fn) == 0:\n",
    "            rec = 0\n",
    "        else:\n",
    "            rec = tp / (tp + fn)\n",
    "        if (prec+rec) == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = (2*(prec*rec))/(prec+rec)\n",
    "            \n",
    "        jac = tp / union\n",
    "        \n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "        jaccards.append(jac)\n",
    "    print('Precision - ', round(np.mean(precisions), 2))\n",
    "    print('Recall - ', round(np.mean(recalls), 2))\n",
    "    print('F1 - ', round(np.mean(f1s), 2))\n",
    "    print('Jaccard - ', round(np.mean(jaccards), 2))\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  1.0\n",
      "Recall -  1.0\n",
      "F1 -  1.0\n",
      "Jaccard -  1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим какие обычно ключевые слова. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тупое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте не будем думать, а попробуем сразу придумать какое-то решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем первые 5 слов из заголовка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.06\n",
      "Recall -  0.06\n",
      "F1 -  0.06\n",
      "Jaccard -  0.03\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['title'].apply(lambda x: x.lower().split()[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.06\n",
      "Recall -  0.07\n",
      "F1 -  0.06\n",
      "Jaccard -  0.03\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['title'].apply(lambda x: x.lower().split()[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем взять самые частотные слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.02\n",
      "Recall -  0.04\n",
      "F1 -  0.02\n",
      "Jaccard -  0.01\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content'].apply(lambda x: [x[0] for x in Counter(x.lower().split()).most_common(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или вообще рандомные слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.0\n",
      "Recall -  0.01\n",
      "F1 -  0.01\n",
      "Jaccard -  0.0\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content'].apply(lambda x: np.random.choice(list(set(x.lower().split())), 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте посмотрим, что вообще извлекается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [\"молодежное, \"яблоко\":, оппозиционная, деятельность, становится, опасной]\n",
       "1                                                                 [\"газпрома\", на, всех, не, хватит]\n",
       "2                                                   [бесконечная, партия, в, четырехмерные, шахматы]\n",
       "3    [экс-депутат,, осужденная, за, фальсификацию, выборов,, оказалась, членом, \"боевого, братства\"]\n",
       "4                               [новая, москва, останется, территорией, экологической, безопасности]\n",
       "5                                [f1., гран-при, сша, прошел, без, четырех, машин, и, со, «стопкой»]\n",
       "6                                          [100, ведущих, политиков, россии, в, феврале, 2018, года]\n",
       "7                                               [закон, \"о, культуре\", принимают, на, фоне, арестов]\n",
       "8                                    [насколько, реальна, газовая, подоплека, сирийского, конфликта]\n",
       "9                                  [фсб:, в, калужской, области, задержаны, четверо, участников, иг]\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title'].apply(lambda x: x.lower().split()[:10]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         [в, и, на, что, не, –, его, «молодежное, с, из]\n",
       "1                                              [в, и, на, –, млрд., куб., по, к, газа, м]\n",
       "2                                                   [в, –, и, не, я, но, что, это, на, с]\n",
       "3                                         [в, на, и, ким, –, по, что, он, видео, зинаиды]\n",
       "4                             [в, и, на, новой, площадью, –, с, развития, москвы, парков]\n",
       "5                                               [в, на, и, не, с, но, уже, что, у, гонки]\n",
       "6                                    [на, в, (с, место)., и, рф, позиции, влияние, по, с]\n",
       "7                                          [в, и, –, по, с, культуре, будет, из, не, как]\n",
       "8                                                [в, и, на, с, что, для, по, –, газа, не]\n",
       "9    [в, террористической, организации, –, задержаны, рф, он, по, возглавляемой, «спящей]\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content'].apply(lambda x: [x[0] for x in Counter(x.lower().split()).most_common(10)]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда выбираются самые частотные слова, выбираются всякие стоп-слова. Также из-за плохой токенизации некоторые слова в обоих списках - пунктуация или слова с пунктуацией на концах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очищаем текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "punct = set(punctuation+'«»—…“”*№–')\n",
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "def delete_punct_on_edges(word):\n",
    "    if len(word) < 2:\n",
    "        \n",
    "        if not word or word in punct:\n",
    "            return None\n",
    "        else:\n",
    "            # если какая-то буква то выдаем\n",
    "            return word\n",
    "\n",
    "    if word[0] not in punct:\n",
    "\n",
    "        if word[-1] not in punct:\n",
    "            return word\n",
    "        else:\n",
    "            return delete_punct_on_edges(word[:-1])\n",
    "    else:\n",
    "        return delete_punct_on_edges(word[1:])\n",
    "      \n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    words = [delete_punct_on_edges(word) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm'] = data['content'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_norm'] = data['title'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [молодёжный, яблоко, оппозиционный, деятельность, становиться, опасный]\n",
       "1                                                                 [газпром, хватить]\n",
       "2                                      [бесконечный, партия, четырехмерный, шахматы]\n",
       "3    [экс-депутат, осудить, фальсификация, выбор, оказаться, член, боевой, братство]\n",
       "4                 [новый, москва, остаться, территория, экологический, безопасность]\n",
       "5                         [f1, гран-при, сша, пройти, четыре, машина, стопка, штраф]\n",
       "6                                [100, ведущий, политик, россия, февраль, 2018, год]\n",
       "7                                           [закон, культура, принимать, фон, арест]\n",
       "8                     [насколько, реальный, газовый, подоплёка, сирийский, конфликт]\n",
       "9                       [фсб, калужский, область, задержать, четверо, участник, иго]\n",
       "Name: title_norm, dtype: object"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_norm'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.11\n",
      "Recall -  0.21\n",
      "F1 -  0.14\n",
      "Jaccard -  0.08\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.14\n",
      "F1 -  0.12\n",
      "Jaccard -  0.07\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'],data['title_norm'].apply(lambda x: x[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество сильно улучшилось! Можно теперь ещё раз посмотреть, что плохого извлекается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [яблоко, молодёжный, который, год, акция, активист, это, деятельность, наш, политика]\n",
       "1                               [миллиард, газа, год, куб, метр, газпром, добыча, который, должный, 2020]\n",
       "2                                          [год, это, книга, роман, писать, тот, выйти, один, мир, очень]\n",
       "3                      [ким, зинаида, видео, журналист, год, судебный, бывший, свидетель, рубль, который]\n",
       "4                      [площадь, новый, территория, москва, га, который, тинао, парк, парковый, развитие]\n",
       "5                                [гонка, который, команда, позиция, место, два, один, круг, из-за, пилот]\n",
       "6               [место, влияние, рф, позиция, глава, россия, президент, политический, сергей, российский]\n",
       "7                [культура, закон, стд, который, сфера, предложить, разработать, быть, концепция, услуга]\n",
       "8                        [газопровод, сирия, год, турция, газа, россия, европа, катар, который, турецкий]\n",
       "9        [организация, цос, участник, рф, террористический, задержать, центр, сообщить, говориться, 2018]\n",
       "10                        [тихон, стихомант, это, старик, журибеда, время, казак, сэмена, говорить, отец]\n",
       "11                    [жильё, метр, кв, год, миллион, жилищный, население, строительство, спрос, прогноз]\n",
       "12                [российский, зритель, стать, кино, театр, год, хороший, результат, аудитория, получить]\n",
       "13                    [революция, фестиваль, ленин, фильм, хороший, награда, миронов, делать, один, роль]\n",
       "14               [вечер, фёдоров, книга, балашов, который, виктория, произведение, женщина, герой, елена]\n",
       "15    [который, сирийский, переговоры, сторона, франция, резолюция, макрон, оон, президент, гуманитарный]\n",
       "16                                   [суд, рф, кс, акционер, юкос, запрос, человек, еспч, минюст, бывший]\n",
       "17            [электромобиль, год, тысяча, кобальт, который, компания, аккумулятор, это, автомобиль, том]\n",
       "18                        [хороший, фильм, оскар, год, главный, один, который, стать, церемония, женщина]\n",
       "19                   [трасса, сабина, нюрбургринг, wtcc, пилотесса, гонка, тс1, автомобиль, шмитц, также]\n",
       "Name: content_norm, dtype: object"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё остались некоторые стоп-слова. Вместо того, чтобы расширять список, давайте попробуем отсеить несуществительные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \n",
    "    words = [delete_punct_on_edges(word) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
    "    words = [word.normal_form for word in words if word.tag.POS == 'NOUN']\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm'] = data['content'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.17\n",
      "Recall -  0.17\n",
      "F1 -  0.16\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещу улучшения!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [яблоко, год, акция, активист, деятельность, политика, власть, человек, жизнь, выборы]\n",
       "1               [миллиард, год, куб, газа, метр, газпром, добыча, производитель, страна, прогноз]\n",
       "2                   [год, книга, роман, мир, жанр, стихотворение, перевод, читатель, том, россия]\n",
       "3         [ким, зинаида, видео, год, журналист, экспертиза, свидетель, рубль, процесс, заседание]\n",
       "4                   [площадь, москва, территория, га, тинао, парка, парк, столица, развитие, год]\n",
       "5                  [гонка, команда, позиция, место, круг, пилот, бокс, чемпионат, заезд, дженсон]\n",
       "6               [место, влияние, рф, позиция, глава, россия, президент, сергей, рейтинг, участие]\n",
       "7    [культура, закон, сфера, учреждение, изменение, концепция, услуга, проект, сообщество, дело]\n",
       "8                    [газопровод, сирия, год, турция, газа, европа, россия, катар, поток, проект]\n",
       "9          [организация, участник, рф, центр, ячейка, эмиссар, область, сирия, деятельность, год]\n",
       "Name: content_norm, dtype: object"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не очень значимые слова все ещё остались. Давайте попробуем отсеять стоп-слова с помощью idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm_str'] = data['content'].apply(lambda x: ' '.join(normalize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(data['content_norm_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_vectors = tfidf.transform(data['content_norm_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [[id2word[w] for w in top] for top in texts_vectors.toarray().argsort()[:,:-6:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко', 'активист', 'акция', 'дарья', 'деятельность'],\n",
       " ['миллиард куб', 'куб метр', 'куб', 'газпром', 'газа'],\n",
       " ['роман', 'книга', 'жанр', 'стихотворение', 'перевод'],\n",
       " ['ким', 'зинаида', 'видео', 'экспертиза', 'свидетель'],\n",
       " ['га', 'площадь', 'парка', 'парк', 'площадь га'],\n",
       " ['гонка', 'команда', 'бокс', 'баттон', 'позиция'],\n",
       " ['го', 'влияние', 'место', 'рф', 'позиция'],\n",
       " ['культура', 'закон', 'сфера услуга', 'концепция', 'учреждение'],\n",
       " ['газопровод', 'катар', 'сирия', 'турция', 'газа'],\n",
       " ['рф организация', 'год участник', 'участник', 'территория сирия', 'ячейка']]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.18\n",
      "Recall -  0.18\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сильного улучшения нет. Немного подросла точность. Теперь вместо стоп-слов в ключевые попадают имена и все такое. Иногда это хорощо, а иногда нет (собянин - может быть ключевым словом, а дарья - вряд ли)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем графы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kws(text, top=5, window_size=5):\n",
    "\n",
    "    vocab = set(text)\n",
    "    word2id = {w:i for i, w in enumerate(vocab)}\n",
    "    id2word = {i:w for i, w in enumerate(vocab)}\n",
    "    # преобразуем слова в индексы для удобства\n",
    "    ids = [word2id[word] for word in text]\n",
    "\n",
    "    # создадим матрицу совстречаемости\n",
    "    m = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "    # пройдемся окном по всему тексту\n",
    "    for i in range(0, len(ids), window_size):\n",
    "        window = ids[i:i+window_size]\n",
    "        # добавим единичку всем парам слов в этом окне\n",
    "        for j, k in combinations(window, 2):\n",
    "            # чтобы граф был направленный \n",
    "            m[j][k] += 1\n",
    "            m[k][j] += 1\n",
    "    \n",
    "    # нормализуем строки, чтобы получилась вероятность перехода\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i] /= np.sum(m[i])\n",
    "    \n",
    "    # случайно выберем первое слова, а затем будет выбирать на основе полученых распределений\n",
    "    # сделаем так 5 раз и добавим каждое слово в счетчик\n",
    "    # чтобы не забиться в одном круге, иногда будет перескакивать на случайное слово\n",
    "    \n",
    "    c = Counter()\n",
    "    n = np.random.choice(len(vocab))\n",
    "    for i in range(1000):\n",
    "        \n",
    "        j = np.random.randint(1,10)\n",
    "        if j > 8:\n",
    "            n = np.random.choice(len(vocab))\n",
    "        n = take_step(n, m)\n",
    "        c.update([n])\n",
    "    \n",
    "    # вернем топ-N наиболее часто встретившихся сл\n",
    "    return [id2word[i] for i, count in c.most_common(top)]\n",
    "\n",
    "def take_step(n, matrix):\n",
    "    rang = len(matrix[n])\n",
    "    next_n = np.random.choice(range(rang), p=matrix[n])\n",
    "    return next_n\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 s, sys: 0 ns, total: 50 s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "keywords_rw = data['content_norm'].apply(lambda x: get_kws(x, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.11\n",
      "Recall -  0.22\n",
      "F1 -  0.14\n",
      "Jaccard -  0.08\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keywords_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [яблоко, год, активист, акция, сторона, политика, украина, убийство, молодая, жизнь]\n",
       "1                                 [миллиард, газпром, газа, куб, год, метр, добыча, цена, производитель, страна]\n",
       "2                                   [год, книга, роман, мениппея, россия, поэзия, москва, работа, перевод, жанр]\n",
       "3                        [ким, зинаида, видео, журналист, год, подсудимая, свидетель, заседание, губарев, рубль]\n",
       "4                                 [площадь, москва, га, территория, парк, тинао, регион, год, развитие, столица]\n",
       "5                            [гонка, команда, позиция, бокс, круг, место, дженсон, ситуация, строчка, чемпионат]\n",
       "6                            [место, рф, влияние, глава, позиция, президент, россия, сергей, сообщение, алексей]\n",
       "7    [культура, закон, сфера, изменение, законодательство, человек, концепция, сообщество, проект, председатель]\n",
       "8                                     [сирия, год, газопровод, россия, турция, европа, катар, иран, газа, поток]\n",
       "9                       [участник, рф, организация, эмиссар, подготовка, март, фсб, территория, ячейка, область]\n",
       "Name: content_norm, dtype: object"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_rw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(text, window_size=5):\n",
    "    vocab = set(text)\n",
    "    word2id = {w:i for i, w in enumerate(vocab)}\n",
    "    id2word = {i:w for i, w in enumerate(vocab)}\n",
    "    # преобразуем слова в индексы для удобства\n",
    "    ids = [word2id[word] for word in text]\n",
    "\n",
    "    # создадим матрицу совстречаемости\n",
    "    m = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "    # пройдемся окном по всему тексту\n",
    "    for i in range(0, len(ids), window_size):\n",
    "        window = ids[i:i+window_size]\n",
    "        # добавим единичку всем парам слов в этом окне\n",
    "        for j, k in combinations(window, 2):\n",
    "            # чтобы граф был направленный \n",
    "            m[j][k] += 1\n",
    "            m[k][j] += 1\n",
    "    \n",
    "    return m, id2word\n",
    "\n",
    "def some_centrality_measure(text, window_size=5, topn=5):\n",
    "    \n",
    "    matrix, id2word = build_matrix(text, window_size)\n",
    "    G = nx.from_numpy_array(matrix)\n",
    "    # тут можно поставить любую метрику\n",
    "    node2measure = dict(nx.degree(G))\n",
    "    \n",
    "    return [id2word[index] for index,measure in sorted(node2measure.items(), key=lambda x: -x[1])[:topn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, id2word = build_matrix(data['content_norm'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.6 s, sys: 0 ns, total: 6.6 s\n",
      "Wall time: 6.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "keyword_nx = data['content_norm'].apply(lambda x: some_centrality_measure(x, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.12\n",
      "Recall -  0.24\n",
      "F1 -  0.16\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keyword_nx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
